{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script for run sklearn (currently ridge) models\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, log_loss, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from scr.utils import get_folder_file_names, pickle_save, ndcg_scale\n",
    "from scr.params.emb import TRANSFORMER_INFO, CARP_INFO\n",
    "from scr.params.sys import RAND_SEED, SKLEARN_ALPHAS\n",
    "from scr.encoding.encoding_classes import ESMEncoder, CARPEncoder, OnehotEncoder\n",
    "\n",
    "from scr.preprocess.data_process import ProtranDataset\n",
    "\n",
    "# seed\n",
    "random.seed(RAND_SEED)\n",
    "np.random.seed(RAND_SEED)\n",
    "\n",
    "\n",
    "class RunRidge:\n",
    "    \"\"\"A class for running ridge regression\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        encoder_name: str,\n",
    "        reset_param: bool = False,\n",
    "        resample_param: bool = False,\n",
    "        embed_batch_size: int = 128,\n",
    "        flatten_emb: bool | str = False,\n",
    "        embed_folder: str | None = None,\n",
    "        all_embed_layers: bool = False,\n",
    "        seq_start_idx: bool | int = False,\n",
    "        seq_end_idx: bool | int = False,\n",
    "        if_encode_all: bool = True,\n",
    "        alphas: np.ndarray | int = SKLEARN_ALPHAS,\n",
    "        ridge_state: int = RAND_SEED,\n",
    "        ridge_params: dict | None = None,\n",
    "        all_result_folder: str = \"results/sklearn\",\n",
    "        **encoder_params,\n",
    "    ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dataset_path: str, full path to the dataset, in pkl or panda readable format\n",
    "            columns include: sequence, target, set, validation,\n",
    "            mut_name (optional), mut_numb (optional)\n",
    "        - encoder_name: str, the name of the encoder\n",
    "        - reset_param: bool = False, if update the full model to xavier_uniform_\n",
    "        - resample_param: bool = False, if update the full model to xavier_normal_\n",
    "        - embed_batch_size: int, set to 0 to encode all in a single batch\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - embed_folder: str = None, path to presaved embedding\n",
    "        - seq_start_idx: bool | int = False, the index for the start of the sequence\n",
    "        - seq_end_idx: bool | int = False, the index for the end of the sequence\n",
    "        - alphas: np.ndarray, arrays of alphas to be tested\n",
    "        - ridge_state: int = RAND_SEED, seed the ridge regression\n",
    "        - ridge_params: dict | None = None, other ridge regression args\n",
    "        - all_result_folder: str = \"results/train_val_test\", the parent folder for all results\n",
    "        - encoder_params: kwarg, additional parameters for encoding\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_path = dataset_path\n",
    "        self.encoder_name = encoder_name\n",
    "        self.reset_param = reset_param\n",
    "        self.resample_param = resample_param\n",
    "        self.embed_batch_size = embed_batch_size\n",
    "        self.flatten_emb = flatten_emb\n",
    "        self.embed_folder = embed_folder\n",
    "        self.all_embed_layers = all_embed_layers\n",
    "        self.seq_start_idx = seq_start_idx\n",
    "        self.seq_end_idx = seq_end_idx\n",
    "        self.if_encode_all = if_encode_all\n",
    "        self.encoder_params = encoder_params\n",
    "\n",
    "        if not isinstance(alphas, np.ndarray):\n",
    "            alphas = np.array([alphas])\n",
    "        self.alphas = alphas\n",
    "\n",
    "        self.ridge_state = ridge_state\n",
    "        self.ridge_params = ridge_params\n",
    "        self.all_result_folder = all_result_folder\n",
    "\n",
    "        if self.reset_param and \"-rand\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-rand\"\n",
    "\n",
    "        if self.resample_param and \"-stat\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-stat\"\n",
    "\n",
    "        all_ridge_results = {}\n",
    "\n",
    "        if self.encoder_name in TRANSFORMER_INFO.keys():\n",
    "            total_emb_layer = TRANSFORMER_INFO[encoder_name][1] + 1\n",
    "        elif self.encoder_name in CARP_INFO.keys():\n",
    "            total_emb_layer = CARP_INFO[encoder_name][1]\n",
    "        else:\n",
    "            # for onehot\n",
    "            self.encoder_name = \"onehot\"\n",
    "            total_emb_layer = 1\n",
    "\n",
    "        if self.all_embed_layers:\n",
    "            print(\"loading all embed layers...\")\n",
    "            # loader has ALL embedding layers\n",
    "            self.train_ds, self.val_ds, self.test_ds = (\n",
    "                ProtranDataset(\n",
    "                    dataset_path=self.dataset_path,\n",
    "                    subset=subset,\n",
    "                    encoder_name=self.encoder_name,\n",
    "                    reset_param=self.reset_param,\n",
    "                    resample_param=self.resample_param,\n",
    "                    embed_batch_size=self.embed_batch_size,\n",
    "                    flatten_emb=self.flatten_emb,\n",
    "                    embed_folder=self.embed_folder,\n",
    "                    embed_layer=self.embed_layer,\n",
    "                    seq_start_idx=self.seq_start_idx,\n",
    "                    seq_end_idx=self.seq_end_idx,\n",
    "                    if_encode_all=self.if_encode_all,\n",
    "                    **self.encoder_params,\n",
    "                )\n",
    "                for subset in [\"train\", \"val\", \"test\"]\n",
    "            )\n",
    "\n",
    "        for layer in range(total_emb_layer):\n",
    "            all_ridge_results[layer] = self.run_ridge_layer(embed_layer=layer,)\n",
    "\n",
    "        self._all_ridge_results = all_ridge_results\n",
    "\n",
    "    def sk_test(\n",
    "        self, model: sklearn.linear_model, ds: ProtranDataset, embed_layer: int\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for testing sklearn models for a specific layer of embeddings\n",
    "\n",
    "        Args:\n",
    "        - model: sklearn.linear_model, trained model\n",
    "        - ds: ProtranDataset, train, val, or test dataset\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - np.concatenate(pred): np.ndarray, 1D predicted fitness values\n",
    "        - np.concatenate(true): np.ndarry, 1D true fitness values\n",
    "        \"\"\"\n",
    "        return (\n",
    "            model.predict(getattr(ds, \"layer\" + str(embed_layer))).squeeze(),\n",
    "            ds.y.squeeze(),\n",
    "        )\n",
    "\n",
    "    def pick_model(self, embed_layer: int, train_ds: Dataset, val_ds: Dataset):\n",
    "        \"\"\"\n",
    "        A function for picking the best model for given alaphs, meaning\n",
    "        lower train_mse and higher test_ndcg\n",
    "        NOTE: alphas tuning is NOT currently optimal\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - sklearn.linear_model, the model with the best alpha\n",
    "        \"\"\"\n",
    "\n",
    "        # init values for comparison\n",
    "        best_mse = np.Inf\n",
    "        best_ndcg = -1\n",
    "        best_rho = -1\n",
    "        best_model = None\n",
    "\n",
    "        # loop through all alphas\n",
    "        for alpha in self.alphas:\n",
    "\n",
    "            # init model for each alpha\n",
    "            if self.ridge_params is None:\n",
    "                self.ridge_params = {}\n",
    "            model = Ridge(\n",
    "                alpha=alpha, random_state=self.ridge_state, **self.ridge_params\n",
    "            )\n",
    "\n",
    "            # fit the model for a given layer of embedding\n",
    "            fitness_scaler = StandardScaler()\n",
    "\n",
    "            if self.all_embed_layers:\n",
    "                train_ds = self.train_ds\n",
    "                val_ds = self.val_ds\n",
    "\n",
    "            model.fit(\n",
    "                getattr(train_ds, \"layer\" + str(embed_layer)),\n",
    "                fitness_scaler.fit_transform(train_ds.y),\n",
    "            )\n",
    "\n",
    "            # eval the model with train and test\n",
    "            train_pred, train_true = self.sk_test(\n",
    "                model, train_ds, embed_layer=embed_layer\n",
    "            )\n",
    "            val_pred, val_true = self.sk_test(model, val_ds, embed_layer=embed_layer)\n",
    "\n",
    "            # calc the metrics\n",
    "            train_mse = mean_squared_error(train_true, train_pred)\n",
    "            val_ndcg = ndcg_scale(val_true, val_pred)\n",
    "            val_rho = spearmanr(val_true, val_pred)[0]\n",
    "\n",
    "            # update the model if it has lower train_mse and higher val_ndcg\n",
    "            if train_mse < best_mse and val_ndcg > best_ndcg:\n",
    "                best_model = model\n",
    "                best_mse = train_mse\n",
    "                best_ndcg = val_ndcg\n",
    "                best_rho = val_rho\n",
    "\n",
    "        print(f\"best model is {best_model}\")\n",
    "        return best_model\n",
    "\n",
    "    def run_ridge_layer(\n",
    "        self, embed_layer: int,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        A function for running ridge regression for a given layer of embedding\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"train\": {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"val\":   {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"test\":  {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "        \"\"\"\n",
    "\n",
    "        # set up the datasets\n",
    "        if self.all_embed_layers:\n",
    "            ds_list = [self.train_ds, self.val_ds, self.test_ds]\n",
    "        else:\n",
    "            print(f\"Getting embed for {embed_layer}...\")\n",
    "            ds_list = [\n",
    "                ProtranDataset(\n",
    "                    dataset_path=self.dataset_path,\n",
    "                    subset=subset,\n",
    "                    encoder_name=self.encoder_name,\n",
    "                    reset_param=self.reset_param,\n",
    "                    resample_param=self.resample_param,\n",
    "                    embed_batch_size=self.embed_batch_size,\n",
    "                    flatten_emb=self.flatten_emb,\n",
    "                    embed_folder=self.embed_folder,\n",
    "                    embed_layer=embed_layer,\n",
    "                    seq_start_idx=self.seq_start_idx,\n",
    "                    seq_end_idx=self.seq_end_idx,\n",
    "                    if_encode_all=self.if_encode_all,\n",
    "                    **self.encoder_params,\n",
    "                )\n",
    "                for subset in [\"train\", \"val\", \"test\"]\n",
    "            ]\n",
    "\n",
    "        # train and get the best alpha\n",
    "        best_model = self.pick_model(\n",
    "            embed_layer=embed_layer, train_ds=ds_list[0], val_ds=ds_list[1]\n",
    "        )\n",
    "\n",
    "        # init dict for resulted outputs\n",
    "        result_dict = {}\n",
    "\n",
    "        # now test the model with the test data\n",
    "        for subset, ds in zip([\"train\", \"val\", \"test\"], ds_list):\n",
    "            pred, true = self.sk_test(best_model, ds, embed_layer=embed_layer)\n",
    "\n",
    "            result_dict[subset] = {\n",
    "                \"mse\": mean_squared_error(true, pred),\n",
    "                \"pred\": pred,\n",
    "                \"true\": true,\n",
    "                \"ndcg\": ndcg_scale(true, pred),\n",
    "                \"rho\": spearmanr(true, pred),\n",
    "            }\n",
    "\n",
    "        dataset_subfolder, file_name = get_folder_file_names(\n",
    "            parent_folder=self.all_result_folder,\n",
    "            dataset_path=self.dataset_path,\n",
    "            encoder_name=self.encoder_name,\n",
    "            embed_layer=embed_layer,\n",
    "            flatten_emb=self.flatten_emb,\n",
    "        )\n",
    "\n",
    "        print(f\"Saving results for {file_name} to: {dataset_subfolder}...\")\n",
    "        pickle_save(\n",
    "            what2save=result_dict,\n",
    "            where2save=os.path.join(dataset_subfolder, file_name + \".pkl\"),\n",
    "        )\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    @property\n",
    "    def all_ridge_results(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"layer#\": {\n",
    "                        \"train\": {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"val\":   {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"test\":  {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        }\n",
    "        \"\"\"\n",
    "        return self._all_ridge_results\n",
    "\n",
    "\n",
    "class RunSK:\n",
    "    \"\"\"\n",
    "    A class for running sklearn models \n",
    "    [NOT FULLY TESTED YET]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        encoder_name: str,\n",
    "        reset_param: bool = False,\n",
    "        resample_param: bool = False,\n",
    "        embed_batch_size: int = 128,\n",
    "        flatten_emb: bool | str = False,\n",
    "        embed_folder: str | None = None,\n",
    "        seq_start_idx: bool | int = False,\n",
    "        seq_end_idx: bool | int = False,\n",
    "        alphas: np.ndarray | int = SKLEARN_ALPHAS,\n",
    "        sklearn_state: int = RAND_SEED,\n",
    "        sklearn_params: dict | None = None,\n",
    "        all_result_folder: str = \"results/sklearn\",\n",
    "        **encoder_params,\n",
    "    ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dataset_path: str, full path to the dataset, in pkl or panda readable format\n",
    "            columns include: sequence, target, set, validation,\n",
    "            mut_name (optional), mut_numb (optional)\n",
    "        - encoder_name: str, the name of the encoder\n",
    "        - reset_param: bool = False, if update the full model to xavier_uniform_\n",
    "        - resample_param: bool = False, if update the full model to xavier_normal_\n",
    "        - embed_batch_size: int, set to 0 to encode all in a single batch\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - embed_folder: str = None, path to presaved embedding\n",
    "        - seq_start_idx: bool | int = False, the index for the start of the sequence\n",
    "        - seq_end_idx: bool | int = False, the index for the end of the sequence\n",
    "        - alphas: np.ndarray, arrays of alphas to be tested\n",
    "        - sklearn_state: int = RAND_SEED, seed the ridge or logistic regression\n",
    "        - sklearn_params: dict | None = None, other ridge or logistic regression args\n",
    "        - all_result_folder: str = \"results/train_val_test\", the parent folder for all results\n",
    "        - encoder_params: kwarg, additional parameters for encoding\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_path = dataset_path\n",
    "        self.encoder_name = encoder_name\n",
    "        self.reset_param = reset_param\n",
    "        self.resample_param = resample_param\n",
    "        self.flatten_emb = flatten_emb\n",
    "\n",
    "        if not isinstance(alphas, np.ndarray):\n",
    "            alphas = np.array([alphas])\n",
    "        self.alphas = alphas\n",
    "\n",
    "        self.sklearn_state = sklearn_state\n",
    "        self.sklearn_params = sklearn_params\n",
    "        self.all_result_folder = all_result_folder\n",
    "\n",
    "        if self.reset_param and \"-rand\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-rand\"\n",
    "\n",
    "        if self.resample_param and \"-stat\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-stat\"\n",
    "\n",
    "        # loader has ALL embedding layers\n",
    "        self.train_ds, self.val_ds, self.test_ds = (\n",
    "            ProtranDataset(\n",
    "                dataset_path=dataset_path,\n",
    "                subset=subset,\n",
    "                encoder_name=encoder_name,\n",
    "                reset_param=reset_param,\n",
    "                resample_param=resample_param,\n",
    "                embed_batch_size=embed_batch_size,\n",
    "                flatten_emb=flatten_emb,\n",
    "                embed_folder=embed_folder,\n",
    "                seq_start_idx=seq_start_idx,\n",
    "                seq_end_idx=seq_end_idx,\n",
    "                **encoder_params,\n",
    "            )\n",
    "            for subset in [\"train\", \"val\", \"test\"]\n",
    "        )\n",
    "\n",
    "        # pick ridge regression if y numerical\n",
    "        if self.val_ds.y.dtype.kind in \"iufc\":\n",
    "            self.sklearn_model = Ridge\n",
    "\n",
    "        # pick logistic regression if y is categorical\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            self.train_ds.y, self.val_ds.y, self.test_ds.y = [\n",
    "                le.fit_transform(y.flatten())\n",
    "                for y in [self.train_ds.y, self.val_ds.y, self.test_ds.y]\n",
    "            ]\n",
    "            self.sklearn_model = LogisticRegression\n",
    "            # convert alpha to C\n",
    "            self.alphas = 1 / self.alphas\n",
    "            # add other params\n",
    "            if self.sklearn_params is None:\n",
    "                self.sklearn_params[\"multi_class\"] = \"multinomial\"\n",
    "                self.sklearn_params[\"max_iter\"] = 1000\n",
    "\n",
    "        all_sklearn_results = {}\n",
    "\n",
    "        # TODO for easier total_emb_layer\n",
    "        if self.encoder_name in TRANSFORMER_INFO.keys():\n",
    "            total_emb_layer = TRANSFORMER_INFO[encoder_name][1] + 1\n",
    "        elif self.encoder_name in CARP_INFO.keys():\n",
    "            total_emb_layer = CARP_INFO[encoder_name][1]\n",
    "        else:\n",
    "            # for onehot\n",
    "            self.encoder_name = \"onehot\"\n",
    "            total_emb_layer = 1\n",
    "\n",
    "        for layer in range(total_emb_layer):\n",
    "            all_sklearn_results[layer] = self.run_sklearn_layer(embed_layer=layer,)\n",
    "\n",
    "        self._all_sklearn_results = all_sklearn_results\n",
    "\n",
    "    def sk_test(\n",
    "        self, model: sklearn.linear_model, ds: ProtranDataset, embed_layer: int\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for testing sklearn models for a specific layer of embeddings\n",
    "\n",
    "        Args:\n",
    "        - model: sklearn.linear_model, trained model\n",
    "        - ds: ProtranDataset, train, val, or test dataset\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - np.concatenate(pred): np.ndarray, 1D predicted fitness values\n",
    "        - np.concatenate(true): np.ndarry, 1D true fitness values\n",
    "        - \n",
    "        \"\"\"\n",
    "\n",
    "        if self.sklearn_model == Ridge:\n",
    "            pred_prob = None\n",
    "        else:\n",
    "            pred_prob = model.predict_proba(\n",
    "                getattr(ds, \"layer\" + str(embed_layer)).cpu().numpy()\n",
    "            ).squeeze()\n",
    "\n",
    "        return (\n",
    "            model.predict(\n",
    "                getattr(ds, \"layer\" + str(embed_layer)).cpu().numpy()\n",
    "            ).squeeze(),\n",
    "            ds.y.squeeze(),\n",
    "            pred_prob,\n",
    "        )\n",
    "\n",
    "    def pick_model(\n",
    "        self, embed_layer: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for picking the best model for given alaphs, meaning\n",
    "        lower train_mse and higher test_ndcg\n",
    "        NOTE: alphas tuning is NOT currently optimal\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - sklearn.linear_model, the model with the best alpha\n",
    "        \"\"\"\n",
    "\n",
    "        # init values for comparison\n",
    "        if self.sklearn_model == Ridge:\n",
    "            best_mse = np.Inf\n",
    "            best_ndcg = -1\n",
    "            best_rho = -1\n",
    "        else:\n",
    "            best_loss = np.Inf\n",
    "            best_acc = 0\n",
    "            best_auc = 0\n",
    "\n",
    "        best_model = None\n",
    "\n",
    "        # loop through all alphas\n",
    "        for alpha in self.alphas:\n",
    "\n",
    "            # init model for each alpha\n",
    "            if self.sklearn_params is None:\n",
    "                self.sklearn_params = {}\n",
    "            model = self.sklearn_model(\n",
    "                alpha=alpha, random_state=self.sklearn_state, **self.sklearn_params\n",
    "            )\n",
    "\n",
    "            # fit the model for a given layer of embedding\n",
    "            fitness_scaler = StandardScaler()\n",
    "            model.fit(\n",
    "                getattr(self.train_ds, \"layer\" + str(embed_layer)).cpu().numpy(),\n",
    "                fitness_scaler.fit_transform(self.train_ds.y),\n",
    "            )\n",
    "\n",
    "            # eval the model with train and test\n",
    "            train_pred, train_true, train_prob = self.sk_test(\n",
    "                model, self.train_ds, embed_layer=embed_layer\n",
    "            )\n",
    "            val_pred, val_true, val_prob = self.sk_test(\n",
    "                model, self.val_ds, embed_layer=embed_layer\n",
    "            )\n",
    "\n",
    "            if self.sklearn_model == Ridge:\n",
    "                # calc the metrics\n",
    "                train_mse = mean_squared_error(train_true, train_pred)\n",
    "                val_ndcg = ndcg_scale(val_true, val_pred)\n",
    "                val_rho = spearmanr(val_true, val_pred)[0]\n",
    "\n",
    "                # update the model if it has lower train_mse and higher val_ndcg\n",
    "                if train_mse < best_mse and val_ndcg > best_ndcg:\n",
    "                    best_model = model\n",
    "                    best_mse = train_mse\n",
    "                    best_ndcg = val_ndcg\n",
    "                    best_rho = val_rho\n",
    "\n",
    "            else:\n",
    "                # calc the metrics\n",
    "                train_loss = log_loss(train_true, train_prob)\n",
    "                val_acc = accuracy_score(val_true, val_pred)\n",
    "                val_auc = roc_auc_score(val_true, val_prob, multi_class=\"ovo\")\n",
    "\n",
    "                # update the model if it has lower log_loss and higher val_auc\n",
    "                if train_loss < best_loss and val_auc > best_auc:\n",
    "                    best_loss = train_loss\n",
    "                    best_acc = val_acc\n",
    "                    best_auc = val_auc\n",
    "\n",
    "        print(f\"best model is {best_model}\")\n",
    "        return best_model\n",
    "\n",
    "    def run_sklearn_layer(\n",
    "        self, embed_layer: int,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        A function for running ridge or logistics regression for a given layer of embedding\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"train\": {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"val\":   {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"test\":  {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "        \"\"\"\n",
    "\n",
    "        # train and get the best alpha\n",
    "        best_model = self.pick_model(embed_layer=embed_layer,)\n",
    "\n",
    "        # init dict for resulted outputs\n",
    "        result_dict = {}\n",
    "\n",
    "        # now test the model with the test data\n",
    "        for subset, ds in zip(\n",
    "            [\"train\", \"val\", \"test\"], [self.train_ds, self.val_ds, self.test_ds],\n",
    "        ):\n",
    "            pred, true, prob = self.sk_test(best_model, ds, embed_layer=embed_layer)\n",
    "\n",
    "            if self.sklearn_model == Ridge:\n",
    "                result_dict[subset] = {\n",
    "                    \"mse\": mean_squared_error(true, pred),\n",
    "                    \"pred\": pred,\n",
    "                    \"true\": true,\n",
    "                    \"ndcg\": ndcg_scale(true, pred),\n",
    "                    \"rho\": spearmanr(true, pred),\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                result_dict[subset] = {\n",
    "                    \"log\": log_loss(true, prob),\n",
    "                    \"pred\": pred,\n",
    "                    \"prob\": prob,\n",
    "                    \"true\": true,\n",
    "                    \"acc\": accuracy_score(true, pred),\n",
    "                    \"rocauc\": roc_auc_score(true, prob, multi_class=\"ovo\"),\n",
    "                }\n",
    "\n",
    "        dataset_subfolder, file_name = get_folder_file_names(\n",
    "            parent_folder=self.all_result_folder,\n",
    "            dataset_path=self.dataset_path,\n",
    "            encoder_name=self.encoder_name,\n",
    "            embed_layer=embed_layer,\n",
    "            flatten_emb=self.flatten_emb,\n",
    "        )\n",
    "\n",
    "        print(f\"Saving results for {file_name} to: {dataset_subfolder}...\")\n",
    "        pickle_save(\n",
    "            what2save=result_dict,\n",
    "            where2save=os.path.join(dataset_subfolder, file_name + \".pkl\"),\n",
    "        )\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    @property\n",
    "    def all_sklearn_results(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"layer#\": {\n",
    "                        \"train\": {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"val\":   {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"test\":  {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        }\n",
    "        \"\"\"\n",
    "        return self._all_sklearn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.params.sys import SKLEARN_ALPHAS, RAND_SEED\n",
    "from scr.model.run_sklearn import RunRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting embed for 0...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Making test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S ...\n",
      "Making test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean ...\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_0 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 1...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_1 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 2...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_2 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 3...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_3 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 4...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_4 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 5...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_5 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 6...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_6 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 7...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_7 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 8...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_8 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 9...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_9 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 10...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_10 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 11...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_11 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 12...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_12 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 13...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_13 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 14...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_14 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 15...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_15 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 16...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_16 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 17...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_17 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 18...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_18 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 19...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_19 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 20...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_20 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 21...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_21 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 22...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_22 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 23...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_23 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 24...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_24 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 25...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_25 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 26...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_26 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 27...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_27 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 28...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_28 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 29...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_29 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 30...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_30 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 31...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_31 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 32...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_32 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 33...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_33 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n",
      "Getting embed for 34...\n",
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t34_670M_UR50S upto 34 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, normalize=True, random_state=42)\n",
      "Saving results for esm1_t34_670M_UR50S-mean-layer_34 to: test/sklearn/proeng/thermo/mixed_split/esm1_t34_670M_UR50S/mean...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<scr.model.run_sklearn.RunRidge at 0x7fa5438156d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunRidge(\n",
    "    dataset_path=\"data/proeng/thermo/mixed_split.csv\",\n",
    "    encoder_name=\"esm1_t34_670M_UR50S\",\n",
    "    # encoder_name=\"esm1_t6_43M_UR50S\",\n",
    "    # encoder_name=\"esm1_t12_85M_UR50S\",\n",
    "    # encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "    reset_param= False,\n",
    "    resample_param = False,\n",
    "    embed_batch_size = 128,\n",
    "    flatten_emb = \"mean\",\n",
    "    embed_folder = \"embeddings/proeng/thermo/mixed_split\",\n",
    "    all_embed_layers=False,\n",
    "    seq_start_idx = False,\n",
    "    seq_end_idx = False,\n",
    "    if_encode_all=False,\n",
    "    alphas = SKLEARN_ALPHAS,\n",
    "    ridge_state= RAND_SEED,\n",
    "    ridge_params= {\"normalize\": True},\n",
    "    all_result_folder = \"test/sklearn\",\n",
    "    # **encoder_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': 'True'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"normalize\": \"True\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [10]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"a\":[10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"normalize\":true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.dumps({\"normalize\": True}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
