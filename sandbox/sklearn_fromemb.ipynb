{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script for run sklearn (currently ridge) models\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, log_loss, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from scr.utils import get_folder_file_names, pickle_save, ndcg_scale\n",
    "from scr.params.emb import TRANSFORMER_INFO, CARP_INFO\n",
    "from scr.params.sys import RAND_SEED, SKLEARN_ALPHAS\n",
    "from scr.encoding.encoding_classes import ESMEncoder, CARPEncoder, OnehotEncoder\n",
    "\n",
    "from scr.preprocess.data_process import ProtranDataset, DatasetInfo\n",
    "\n",
    "# seed\n",
    "random.seed(RAND_SEED)\n",
    "np.random.seed(RAND_SEED)\n",
    "\n",
    "\n",
    "class RunRidge:\n",
    "    \"\"\"A class for running ridge regression\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        encoder_name: str,\n",
    "        reset_param: bool = False,\n",
    "        resample_param: bool = False,\n",
    "        embed_batch_size: int = 128,\n",
    "        flatten_emb: bool | str = False,\n",
    "        embed_folder: str | None = None,\n",
    "        all_embed_layers: bool = True,\n",
    "        seq_start_idx: bool | int = False,\n",
    "        seq_end_idx: bool | int = False,\n",
    "        if_encode_all: bool = True,\n",
    "        alphas: np.ndarray | int = SKLEARN_ALPHAS,\n",
    "        ridge_state: int = RAND_SEED,\n",
    "        ridge_params: dict | None = None,\n",
    "        all_result_folder: str = \"results/sklearn\",\n",
    "        **encoder_params,\n",
    "    ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dataset_path: str, full path to the dataset, in pkl or panda readable format\n",
    "            columns include: sequence, target, set, validation,\n",
    "            mut_name (optional), mut_numb (optional)\n",
    "        - encoder_name: str, the name of the encoder\n",
    "        - reset_param: bool = False, if update the full model to xavier_uniform_\n",
    "        - resample_param: bool = False, if update the full model to xavier_normal_\n",
    "        - embed_batch_size: int, set to 0 to encode all in a single batch\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - embed_folder: str = None, path to presaved embedding\n",
    "        - all_embed_layers: bool = True, if include all embed layers\n",
    "        - seq_start_idx: bool | int = False, the index for the start of the sequence\n",
    "        - seq_end_idx: bool | int = False, the index for the end of the sequence\n",
    "        - if_encode_all: bool = True, if encode all embed layers all at once\n",
    "        - alphas: np.ndarray, arrays of alphas to be tested\n",
    "        - ridge_state: int = RAND_SEED, seed the ridge regression\n",
    "        - ridge_params: dict | None = None, other ridge regression args\n",
    "        - all_result_folder: str = \"results/train_val_test\", the parent folder for all results\n",
    "        - encoder_params: kwarg, additional parameters for encoding\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_path = dataset_path\n",
    "        self.encoder_name = encoder_name\n",
    "        self.reset_param = reset_param\n",
    "        self.resample_param = resample_param\n",
    "        self.embed_batch_size = embed_batch_size\n",
    "        self.flatten_emb = flatten_emb\n",
    "        self.embed_folder = embed_folder\n",
    "        self.all_embed_layers = all_embed_layers\n",
    "        self.seq_start_idx = seq_start_idx\n",
    "        self.seq_end_idx = seq_end_idx\n",
    "        self.if_encode_all = if_encode_all\n",
    "        self.encoder_params = encoder_params\n",
    "\n",
    "        if not isinstance(alphas, np.ndarray):\n",
    "            alphas = np.array([alphas])\n",
    "        self.alphas = alphas\n",
    "\n",
    "        self.ridge_state = ridge_state\n",
    "        self.ridge_params = ridge_params\n",
    "        self.all_result_folder = all_result_folder\n",
    "\n",
    "        if self.reset_param and \"-rand\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-rand\"\n",
    "\n",
    "        if self.resample_param and \"-stat\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-stat\"\n",
    "\n",
    "        all_ridge_results = {}\n",
    "\n",
    "        if self.encoder_name in TRANSFORMER_INFO.keys():\n",
    "            total_emb_layer = TRANSFORMER_INFO[encoder_name][1] + 1\n",
    "        elif self.encoder_name in CARP_INFO.keys():\n",
    "            total_emb_layer = CARP_INFO[encoder_name][1]\n",
    "        else:\n",
    "            # for onehot\n",
    "            self.encoder_name = \"onehot\"\n",
    "            total_emb_layer = 1\n",
    "\n",
    "        if self.all_embed_layers:\n",
    "            print(\"loading all embed layers...\")\n",
    "            # loader has ALL embedding layers\n",
    "            self.train_ds, self.val_ds, self.test_ds = (\n",
    "                ProtranDataset(\n",
    "                    dataset_path=self.dataset_path,\n",
    "                    subset=subset,\n",
    "                    encoder_name=self.encoder_name,\n",
    "                    reset_param=self.reset_param,\n",
    "                    resample_param=self.resample_param,\n",
    "                    embed_batch_size=self.embed_batch_size,\n",
    "                    flatten_emb=self.flatten_emb,\n",
    "                    embed_folder=self.embed_folder,\n",
    "                    embed_layer=None,\n",
    "                    seq_start_idx=self.seq_start_idx,\n",
    "                    seq_end_idx=self.seq_end_idx,\n",
    "                    if_encode_all=self.if_encode_all,\n",
    "                    **self.encoder_params,\n",
    "                )\n",
    "                for subset in [\"train\", \"val\", \"test\"]\n",
    "            )\n",
    "\n",
    "        for layer in range(total_emb_layer):\n",
    "            all_ridge_results[layer] = self.run_ridge_layer(embed_layer=layer,)\n",
    "\n",
    "        self._all_ridge_results = all_ridge_results\n",
    "\n",
    "    def sk_test(\n",
    "        self, model: sklearn.linear_model, ds: ProtranDataset, embed_layer: int\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for testing sklearn models for a specific layer of embeddings\n",
    "\n",
    "        Args:\n",
    "        - model: sklearn.linear_model, trained model\n",
    "        - ds: ProtranDataset, train, val, or test dataset\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - np.concatenate(pred): np.ndarray, 1D predicted fitness values\n",
    "        - np.concatenate(true): np.ndarry, 1D true fitness values\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            model.predict(getattr(ds, \"layer\" + str(embed_layer))).squeeze(),\n",
    "            # getattr(train_ds, \"layer\" + str(embed_layer))\n",
    "            ds.y.squeeze(),\n",
    "        )\n",
    "\n",
    "    def pick_model(\n",
    "        self, embed_layer: int, train_ds: ProtranDataset, val_ds: ProtranDataset\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for picking the best model for given alaphs, meaning\n",
    "        lower train_mse and higher test_ndcg\n",
    "        NOTE: alphas tuning is NOT currently optimal\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - sklearn.linear_model, the model with the best alpha\n",
    "        \"\"\"\n",
    "\n",
    "        # init values for comparison\n",
    "        best_mse = np.Inf\n",
    "        best_ndcg = -1\n",
    "        best_rho = -1\n",
    "        best_model = None\n",
    "\n",
    "        # loop through all alphas\n",
    "        for alpha in self.alphas:\n",
    "\n",
    "            # init model for each alpha\n",
    "            if self.ridge_params is None:\n",
    "                self.ridge_params = {}\n",
    "            model = Ridge(\n",
    "                alpha=alpha, random_state=self.ridge_state, **self.ridge_params\n",
    "            )\n",
    "\n",
    "            # fit the model for a given layer of embedding\n",
    "            fitness_scaler = StandardScaler()\n",
    "\n",
    "            if self.all_embed_layers:\n",
    "                train_ds = self.train_ds\n",
    "                val_ds = self.val_ds\n",
    "\n",
    "            model.fit(\n",
    "                getattr(train_ds, \"layer\" + str(embed_layer)),\n",
    "                fitness_scaler.fit_transform(train_ds.y),\n",
    "            )\n",
    "\n",
    "            # eval the model with train and test\n",
    "            train_pred, train_true = self.sk_test(\n",
    "                model, train_ds, embed_layer=embed_layer\n",
    "            )\n",
    "            val_pred, val_true = self.sk_test(model, val_ds, embed_layer=embed_layer)\n",
    "\n",
    "            # calc the metrics\n",
    "            train_mse = mean_squared_error(train_true, train_pred)\n",
    "            val_ndcg = ndcg_scale(val_true, val_pred)\n",
    "            val_rho = spearmanr(val_true, val_pred)[0]\n",
    "\n",
    "            # update the model if it has lower train_mse and higher val_ndcg\n",
    "            if train_mse < best_mse and val_ndcg > best_ndcg:\n",
    "                best_model = model\n",
    "                best_mse = train_mse\n",
    "                best_ndcg = val_ndcg\n",
    "                best_rho = val_rho\n",
    "\n",
    "        print(f\"best model is {best_model}\")\n",
    "\n",
    "        return best_model\n",
    "\n",
    "    def run_ridge_layer(\n",
    "        self, embed_layer: int,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        A function for running ridge regression for a given layer of embedding\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"train\": {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"val\":   {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"test\":  {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "        \"\"\"\n",
    "\n",
    "        # set up the datasets\n",
    "        if self.all_embed_layers:\n",
    "            ds_list = [self.train_ds, self.val_ds, self.test_ds]\n",
    "        else:\n",
    "            print(f\"Getting embed for {embed_layer}...\")\n",
    "            ds_list = [\n",
    "                ProtranDataset(\n",
    "                    dataset_path=self.dataset_path,\n",
    "                    subset=subset,\n",
    "                    encoder_name=self.encoder_name,\n",
    "                    reset_param=self.reset_param,\n",
    "                    resample_param=self.resample_param,\n",
    "                    embed_batch_size=self.embed_batch_size,\n",
    "                    flatten_emb=self.flatten_emb,\n",
    "                    embed_folder=self.embed_folder,\n",
    "                    embed_layer=embed_layer,\n",
    "                    seq_start_idx=self.seq_start_idx,\n",
    "                    seq_end_idx=self.seq_end_idx,\n",
    "                    if_encode_all=self.if_encode_all,\n",
    "                    **self.encoder_params,\n",
    "                )\n",
    "                for subset in [\"train\", \"val\", \"test\"]\n",
    "            ]\n",
    "\n",
    "        # train and get the best alpha\n",
    "        best_model = self.pick_model(\n",
    "            embed_layer=embed_layer, train_ds=ds_list[0], val_ds=ds_list[1]\n",
    "        )\n",
    "\n",
    "        # init dict for resulted outputs\n",
    "        result_dict = {}\n",
    "\n",
    "        # now test the model with the test data\n",
    "        for subset, ds in zip([\"train\", \"val\", \"test\"], ds_list):\n",
    "            pred, true = self.sk_test(best_model, ds, embed_layer=embed_layer)\n",
    "\n",
    "            result_dict[subset] = {\n",
    "                \"mse\": mean_squared_error(true, pred),\n",
    "                \"pred\": pred,\n",
    "                \"true\": true,\n",
    "                \"ndcg\": ndcg_scale(true, pred),\n",
    "                \"rho\": spearmanr(true, pred),\n",
    "            }\n",
    "\n",
    "        dataset_subfolder, file_name = get_folder_file_names(\n",
    "            parent_folder=self.all_result_folder,\n",
    "            dataset_path=self.dataset_path,\n",
    "            encoder_name=self.encoder_name,\n",
    "            embed_layer=embed_layer,\n",
    "            flatten_emb=self.flatten_emb,\n",
    "        )\n",
    "\n",
    "        print(f\"Saving results for {file_name} to: {dataset_subfolder}...\")\n",
    "        pickle_save(\n",
    "            what2save=result_dict,\n",
    "            where2save=os.path.join(dataset_subfolder, file_name + \".pkl\"),\n",
    "        )\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    @property\n",
    "    def all_ridge_results(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"layer#\": {\n",
    "                        \"train\": {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"val\":   {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"test\":  {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        }\n",
    "        \"\"\"\n",
    "        return self._all_ridge_results\n",
    "\n",
    "\n",
    "class RunSK:\n",
    "    \"\"\"\n",
    "    A class for running sklearn models \n",
    "    [NOT FULLY TESTED YET]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        encoder_name: str,\n",
    "        reset_param: bool = False,\n",
    "        resample_param: bool = False,\n",
    "        embed_batch_size: int = 128,\n",
    "        flatten_emb: bool | str = False,\n",
    "        embed_folder: str | None = None,\n",
    "        all_embed_layers: bool = True,\n",
    "        seq_start_idx: bool | int = False,\n",
    "        seq_end_idx: bool | int = False,\n",
    "        if_encode_all: bool = True,\n",
    "        alphas: np.ndarray | int = SKLEARN_ALPHAS,\n",
    "        sklearn_state: int = RAND_SEED,\n",
    "        sklearn_params: dict | None = None,\n",
    "        all_result_folder: str = \"results/sklearn\",\n",
    "        **encoder_params,\n",
    "    ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dataset_path: str, full path to the dataset, in pkl or panda readable format\n",
    "            columns include: sequence, target, set, validation,\n",
    "            mut_name (optional), mut_numb (optional)\n",
    "        - encoder_name: str, the name of the encoder\n",
    "        - reset_param: bool = False, if update the full model to xavier_uniform_\n",
    "        - resample_param: bool = False, if update the full model to xavier_normal_\n",
    "        - embed_batch_size: int, set to 0 to encode all in a single batch\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - embed_folder: str = None, path to presaved embedding\n",
    "        - seq_start_idx: bool | int = False, the index for the start of the sequence\n",
    "        - seq_end_idx: bool | int = False, the index for the end of the sequence\n",
    "        - alphas: np.ndarray, arrays of alphas to be tested\n",
    "        - sklearn_state: int = RAND_SEED, seed the ridge or logistic regression\n",
    "        - sklearn_params: dict | None = None, other ridge or logistic regression args\n",
    "        - all_result_folder: str = \"results/train_val_test\", the parent folder for all results\n",
    "        - encoder_params: kwarg, additional parameters for encoding\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_path = dataset_path\n",
    "        self.encoder_name = encoder_name\n",
    "        self.reset_param = reset_param\n",
    "        self.resample_param = resample_param\n",
    "        self.embed_batch_size = embed_batch_size\n",
    "        self.flatten_emb = flatten_emb\n",
    "        self.embed_folder = embed_folder\n",
    "        self.all_embed_layers = all_embed_layers\n",
    "        self.seq_start_idx = seq_start_idx\n",
    "        self.seq_end_idx = seq_end_idx\n",
    "        self.if_encode_all = if_encode_all\n",
    "        self.encoder_params = encoder_params\n",
    "\n",
    "        if not isinstance(alphas, np.ndarray):\n",
    "            alphas = np.array([alphas])\n",
    "        self.alphas = alphas\n",
    "\n",
    "        self.sklearn_state = sklearn_state\n",
    "        self.sklearn_params = sklearn_params\n",
    "        self.all_result_folder = all_result_folder\n",
    "\n",
    "        if self.reset_param and \"-rand\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-rand\"\n",
    "\n",
    "        if self.resample_param and \"-stat\" not in self.all_result_folder:\n",
    "            self.all_result_folder = f\"{self.all_result_folder}-stat\"\n",
    "\n",
    "        # update encoder name and total embedding layers\n",
    "        if self.encoder_name in TRANSFORMER_INFO.keys():\n",
    "            total_emb_layer = TRANSFORMER_INFO[encoder_name][1] + 1\n",
    "        elif self.encoder_name in CARP_INFO.keys():\n",
    "            total_emb_layer = CARP_INFO[encoder_name][1]\n",
    "        else:\n",
    "            # for onehot\n",
    "            self.encoder_name = \"onehot\"\n",
    "            total_emb_layer = 1\n",
    "\n",
    "        # if self.all_embed_layers:\n",
    "        #    print(\"loading all embed layers...\")\n",
    "        # loader has ALL embedding layers\n",
    "        self.train_ds, self.val_ds, self.test_ds = (\n",
    "            ProtranDataset(\n",
    "                dataset_path=self.dataset_path,\n",
    "                subset=subset,\n",
    "                encoder_name=self.encoder_name,\n",
    "                reset_param=self.reset_param,\n",
    "                resample_param=self.resample_param,\n",
    "                embed_batch_size=self.embed_batch_size,\n",
    "                flatten_emb=self.flatten_emb,\n",
    "                embed_folder=self.embed_folder,\n",
    "                embed_layer=None,\n",
    "                seq_start_idx=self.seq_start_idx,\n",
    "                seq_end_idx=self.seq_end_idx,\n",
    "                if_encode_all=self.if_encode_all,\n",
    "                **self.encoder_params,\n",
    "            )\n",
    "            for subset in [\"train\", \"val\", \"test\"]\n",
    "        )\n",
    "\n",
    "        self._ds_info = DatasetInfo(self.dataset_path)\n",
    "        self._model_type = self._ds_info.model_type\n",
    "        self._numb_class = self._ds_info.numb_class\n",
    "\n",
    "        print(f\"Running {self._model_type}...\")\n",
    "\n",
    "        # pick ridge regression if y numerical\n",
    "        if self._model_type == \"LinearRegression\":\n",
    "            self.sklearn_model = Ridge\n",
    "\n",
    "        # pick logistic regression if y is categorical\n",
    "        elif self._model_type == \"LinearClassifier\":\n",
    "            \n",
    "            \"\"\"le = LabelEncoder()\n",
    "            self.train_ds.y, self.val_ds.y, self.test_ds.y = [\n",
    "                le.fit_transform(y.flatten())\n",
    "                for y in [self.train_ds.y, self.val_ds.y, self.test_ds.y]\n",
    "            ]\"\"\"\n",
    "            self.sklearn_model = LogisticRegression\n",
    "            # convert alpha to C\n",
    "            self.alphas = 1 / self.alphas\n",
    "            # add other params\n",
    "            if self.sklearn_params is None:\n",
    "                self.sklearn_params = {}\n",
    "                self.sklearn_params[\"multi_class\"] = \"multinomial\"\n",
    "                self.sklearn_params[\"max_iter\"] = 10000\n",
    "\n",
    "        all_sklearn_results = {}\n",
    "\n",
    "        for layer in range(total_emb_layer):\n",
    "            all_sklearn_results[layer] = self.run_sklearn_layer(embed_layer=layer,)\n",
    "\n",
    "        self._all_sklearn_results = all_sklearn_results\n",
    "\n",
    "    def sk_test(\n",
    "        self, model: sklearn.linear_model, ds: ProtranDataset, embed_layer: int\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for testing sklearn models for a specific layer of embeddings\n",
    "\n",
    "        Args:\n",
    "        - model: sklearn.linear_model, trained model\n",
    "        - ds: ProtranDataset, train, val, or test dataset\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - np.concatenate(pred): np.ndarray, 1D predicted fitness values\n",
    "        - np.concatenate(true): np.ndarry, 1D true fitness values\n",
    "        - \n",
    "        \"\"\"\n",
    "\n",
    "        if self.sklearn_model == Ridge:\n",
    "            pred_prob = None\n",
    "        else:\n",
    "            pred_prob = model.predict_proba(\n",
    "                getattr(ds, \"layer\" + str(embed_layer))\n",
    "            ).squeeze()\n",
    "\n",
    "        return (\n",
    "            model.predict(getattr(ds, \"layer\" + str(embed_layer))).squeeze(),\n",
    "            ds.y.squeeze(),\n",
    "            pred_prob,\n",
    "        )\n",
    "\n",
    "    def pick_model(\n",
    "        self, embed_layer: int, train_ds: ProtranDataset, val_ds: ProtranDataset\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A function for picking the best model for given alaphs, meaning\n",
    "        lower train_mse and higher test_ndcg\n",
    "        NOTE: alphas tuning is NOT currently optimal\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - sklearn.linear_model, the model with the best alpha\n",
    "        \"\"\"\n",
    "\n",
    "        # init values for comparison\n",
    "        if self.sklearn_model == Ridge:\n",
    "            best_mse = np.Inf\n",
    "            best_ndcg = -1\n",
    "            best_rho = -1\n",
    "        else:\n",
    "            best_loss = np.Inf\n",
    "            best_acc = 0\n",
    "            best_auc = 0\n",
    "\n",
    "        best_model = None\n",
    "\n",
    "        # loop through all alphas\n",
    "        for alpha in self.alphas:\n",
    "\n",
    "            # init model for each alpha\n",
    "            if self.sklearn_params is None:\n",
    "                self.sklearn_params = {}\n",
    "\n",
    "            if self._model_type == \"LinearRegression\":\n",
    "                self.sklearn_params[\"alpha\"] = alpha\n",
    "            elif self._model_type == \"LinearClassifier\":\n",
    "                self.sklearn_params[\"C\"] = alpha\n",
    "\n",
    "            model = self.sklearn_model(\n",
    "                random_state=self.sklearn_state, **self.sklearn_params\n",
    "            )\n",
    "            \n",
    "            # fit the model for a given layer of embedding\n",
    "            fitness_scaler = StandardScaler()\n",
    "\n",
    "            if self.all_embed_layers:\n",
    "                train_ds = self.train_ds\n",
    "                val_ds = self.val_ds\n",
    "\n",
    "            if self._model_type == \"LinearRegression\":\n",
    "                y = fitness_scaler.fit_transform(train_ds.y)\n",
    "            else:\n",
    "                y = train_ds.y.ravel()\n",
    "\n",
    "            model.fit(getattr(train_ds, \"layer\" + str(embed_layer)), y)\n",
    "\n",
    "            # eval the model with train and test\n",
    "            train_pred, train_true, train_prob = self.sk_test(\n",
    "                model, train_ds, embed_layer=embed_layer\n",
    "            )\n",
    "            val_pred, val_true, val_prob = self.sk_test(\n",
    "                model, val_ds, embed_layer=embed_layer\n",
    "            )\n",
    "\n",
    "            if self.sklearn_model == Ridge:\n",
    "                # calc the metrics\n",
    "                train_mse = mean_squared_error(train_true, train_pred)\n",
    "                val_ndcg = ndcg_scale(val_true, val_pred)\n",
    "                val_rho = spearmanr(val_true, val_pred)[0]\n",
    "\n",
    "                # update the model if it has lower train_mse and higher val_ndcg\n",
    "                if train_mse < best_mse and val_ndcg > best_ndcg:\n",
    "                    best_model = model\n",
    "                    best_mse = train_mse\n",
    "                    best_ndcg = val_ndcg\n",
    "                    best_rho = val_rho\n",
    "\n",
    "            else:\n",
    "                # calc the metrics\n",
    "                train_loss = log_loss(train_true, train_prob)\n",
    "                val_acc = accuracy_score(val_true, val_pred)\n",
    "                val_auc = roc_auc_score(val_true, val_prob, multi_class=\"ovr\")\n",
    "\n",
    "                # update the model if it has lower log_loss and higher val_auc\n",
    "                if train_loss < best_loss and val_auc > best_auc:\n",
    "                    best_loss = train_loss\n",
    "                    best_acc = val_acc\n",
    "                    best_auc = val_auc\n",
    "\n",
    "        print(f\"best model is {best_model}\")\n",
    "        return best_model\n",
    "\n",
    "    def run_sklearn_layer(\n",
    "        self, embed_layer: int,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        A function for running ridge or logistics regression for a given layer of embedding\n",
    "\n",
    "        Args:\n",
    "        - embed_layer: int, specific layer of the embedding\n",
    "\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"train\": {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"val\":   {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "            \"test\":  {\"mse\": float,\n",
    "                    \"pred\": np.ndarray,\n",
    "                    \"true\": np.ndarray,\n",
    "                    \"ndcg\": float,\n",
    "                    \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "        \"\"\"\n",
    "\n",
    "        # set up the datasets\n",
    "        if self.all_embed_layers:\n",
    "            ds_list = [self.train_ds, self.val_ds, self.test_ds]\n",
    "        else:\n",
    "            print(f\"Getting embed for {embed_layer}...\")\n",
    "            ds_list = [\n",
    "                ProtranDataset(\n",
    "                    dataset_path=self.dataset_path,\n",
    "                    subset=subset,\n",
    "                    encoder_name=self.encoder_name,\n",
    "                    reset_param=self.reset_param,\n",
    "                    resample_param=self.resample_param,\n",
    "                    embed_batch_size=self.embed_batch_size,\n",
    "                    flatten_emb=self.flatten_emb,\n",
    "                    embed_folder=self.embed_folder,\n",
    "                    embed_layer=embed_layer,\n",
    "                    seq_start_idx=self.seq_start_idx,\n",
    "                    seq_end_idx=self.seq_end_idx,\n",
    "                    if_encode_all=self.if_encode_all,\n",
    "                    **self.encoder_params,\n",
    "                )\n",
    "                for subset in [\"train\", \"val\", \"test\"]\n",
    "            ]\n",
    "\n",
    "        # train and get the best alpha\n",
    "        best_model = self.pick_model(\n",
    "            embed_layer=embed_layer, train_ds=ds_list[0], val_ds=ds_list[1]\n",
    "        )\n",
    "\n",
    "        # init dict for resulted outputs\n",
    "        result_dict = {}\n",
    "\n",
    "        # now test the model with the test data\n",
    "        for subset, ds in zip([\"train\", \"val\", \"test\"], ds_list,):\n",
    "            pred, true, prob = self.sk_test(best_model, ds, embed_layer=embed_layer)\n",
    "\n",
    "            if self.sklearn_model == Ridge:\n",
    "                result_dict[subset] = {\n",
    "                    \"mse\": mean_squared_error(true, pred),\n",
    "                    \"pred\": pred,\n",
    "                    \"true\": true,\n",
    "                    \"ndcg\": ndcg_scale(true, pred),\n",
    "                    \"rho\": spearmanr(true, pred),\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                result_dict[subset] = {\n",
    "                    \"log\": log_loss(true, prob),\n",
    "                    \"pred\": pred,\n",
    "                    \"prob\": prob,\n",
    "                    \"true\": true,\n",
    "                    \"acc\": accuracy_score(true, pred),\n",
    "                    \"rocauc\": roc_auc_score(true, prob, multi_class=\"ovr\"),\n",
    "                }\n",
    "\n",
    "        dataset_subfolder, file_name = get_folder_file_names(\n",
    "            parent_folder=self.all_result_folder,\n",
    "            dataset_path=self.dataset_path,\n",
    "            encoder_name=self.encoder_name,\n",
    "            embed_layer=embed_layer,\n",
    "            flatten_emb=self.flatten_emb,\n",
    "        )\n",
    "\n",
    "        print(f\"Saving results for {file_name} to: {dataset_subfolder}...\")\n",
    "        pickle_save(\n",
    "            what2save=result_dict,\n",
    "            where2save=os.path.join(dataset_subfolder, file_name + \".pkl\"),\n",
    "        )\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    @property\n",
    "    def all_sklearn_results(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - dict, with the keys and dict values\n",
    "            \"layer#\": {\n",
    "                        \"train\": {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"val\":   {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        \"test\":  {\"mse\": float,\n",
    "                                \"pred\": np.ndarray,\n",
    "                                \"true\": np.ndarray,\n",
    "                                \"ndcg\": float,\n",
    "                                \"rho\": SpearmanrResults(correlation=float, pvalue=float)}\n",
    "                        }\n",
    "        \"\"\"\n",
    "        return self._all_sklearn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.params.sys import SKLEARN_ALPHAS, RAND_SEED\n",
    "from scr.model.run_sklearn import RunRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LinearRegression...\n",
      "Getting embed for 0...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 0\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 0\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 0\n",
      "before pick model\n",
      "Ridge(alpha=0.001, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n",
      "Ridge(alpha=0.01, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n",
      "Ridge(alpha=0.1, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=5.35783e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n",
      "Ridge(alpha=10.0, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n",
      "best model is Ridge(alpha=0.001, random_state=42)\n",
      "Making test/sklearn/proeng/thermo ...\n",
      "Making test/sklearn/proeng/thermo/mixed_split ...\n",
      "Making test/sklearn/proeng/thermo/mixed_split/esm1_t6_43M_UR50S ...\n",
      "Making test/sklearn/proeng/thermo/mixed_split/esm1_t6_43M_UR50S/mean ...\n",
      "Saving results for esm1_t6_43M_UR50S-mean-layer_0 to: test/sklearn/proeng/thermo/mixed_split/esm1_t6_43M_UR50S/mean...\n",
      "Getting embed for 1...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 1\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 1\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 1\n",
      "before pick model\n",
      "Ridge(alpha=0.001, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=6.37587e-11): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.01, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.94957e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.65884e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.54099e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=10.0, random_state=42)\n",
      "(22335, 1)\n",
      "(22335, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=4.05554e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is Ridge(alpha=0.001, random_state=42)\n",
      "Saving results for esm1_t6_43M_UR50S-mean-layer_1 to: test/sklearn/proeng/thermo/mixed_split/esm1_t6_43M_UR50S/mean...\n",
      "Getting embed for 2...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m RunSK(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m     dataset_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/proeng/thermo/mixed_split.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m# encoder_name=\"esm1_t34_670M_UR50S\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m     encoder_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mesm1_t6_43M_UR50S\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39m# encoder_name=\"esm1_t12_85M_UR50S\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39m# encoder_name=\"esm1b_t33_650M_UR50S\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=6'>7</a>\u001b[0m     reset_param\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=7'>8</a>\u001b[0m     resample_param \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=8'>9</a>\u001b[0m     embed_batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=9'>10</a>\u001b[0m     flatten_emb \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=10'>11</a>\u001b[0m     embed_folder \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39membeddings/proeng/thermo/mixed_split\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=11'>12</a>\u001b[0m     all_embed_layers\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=12'>13</a>\u001b[0m     seq_start_idx \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=13'>14</a>\u001b[0m     seq_end_idx \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=14'>15</a>\u001b[0m     if_encode_all\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=15'>16</a>\u001b[0m     alphas \u001b[39m=\u001b[39;49m SKLEARN_ALPHAS,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m     sklearn_state\u001b[39m=\u001b[39;49m RAND_SEED,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m     \u001b[39m# sklearn_params= {\"normalize\": True},\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=18'>19</a>\u001b[0m     all_result_folder \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtest/sklearn\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=19'>20</a>\u001b[0m     \u001b[39m# **encoder_params,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=20'>21</a>\u001b[0m )\n",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 5\u001b[0m in \u001b[0;36mRunSK.__init__\u001b[0;34m(self, dataset_path, encoder_name, reset_param, resample_param, embed_batch_size, flatten_emb, embed_folder, all_embed_layers, seq_start_idx, seq_end_idx, if_encode_all, alphas, sklearn_state, sklearn_params, all_result_folder, **encoder_params)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=466'>467</a>\u001b[0m all_sklearn_results \u001b[39m=\u001b[39m {}\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=468'>469</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_emb_layer):\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=469'>470</a>\u001b[0m     all_sklearn_results[layer] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_sklearn_layer(embed_layer\u001b[39m=\u001b[39;49mlayer,)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=471'>472</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_sklearn_results \u001b[39m=\u001b[39m all_sklearn_results\n",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 5\u001b[0m in \u001b[0;36mRunSK.run_sklearn_layer\u001b[0;34m(self, embed_layer)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=633'>634</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=634'>635</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGetting embed for \u001b[39m\u001b[39m{\u001b[39;00membed_layer\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=635'>636</a>\u001b[0m     ds_list \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=636'>637</a>\u001b[0m         ProtranDataset(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=637'>638</a>\u001b[0m             dataset_path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=638'>639</a>\u001b[0m             subset\u001b[39m=\u001b[39msubset,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=639'>640</a>\u001b[0m             encoder_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_name,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=640'>641</a>\u001b[0m             reset_param\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_param,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=641'>642</a>\u001b[0m             resample_param\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresample_param,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=642'>643</a>\u001b[0m             embed_batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_batch_size,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=643'>644</a>\u001b[0m             flatten_emb\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten_emb,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=644'>645</a>\u001b[0m             embed_folder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_folder,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=645'>646</a>\u001b[0m             embed_layer\u001b[39m=\u001b[39membed_layer,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=646'>647</a>\u001b[0m             seq_start_idx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_start_idx,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=647'>648</a>\u001b[0m             seq_end_idx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq_end_idx,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=648'>649</a>\u001b[0m             if_encode_all\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_encode_all,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=649'>650</a>\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_params,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=650'>651</a>\u001b[0m         )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=651'>652</a>\u001b[0m         \u001b[39mfor\u001b[39;00m subset \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=652'>653</a>\u001b[0m     ]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=653'>654</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbefore pick model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=654'>655</a>\u001b[0m \u001b[39m# train and get the best alpha\u001b[39;00m\n",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 5\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=633'>634</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=634'>635</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGetting embed for \u001b[39m\u001b[39m{\u001b[39;00membed_layer\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=635'>636</a>\u001b[0m     ds_list \u001b[39m=\u001b[39m [\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=636'>637</a>\u001b[0m         ProtranDataset(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=637'>638</a>\u001b[0m             dataset_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_path,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=638'>639</a>\u001b[0m             subset\u001b[39m=\u001b[39;49msubset,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=639'>640</a>\u001b[0m             encoder_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_name,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=640'>641</a>\u001b[0m             reset_param\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_param,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=641'>642</a>\u001b[0m             resample_param\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresample_param,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=642'>643</a>\u001b[0m             embed_batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_batch_size,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=643'>644</a>\u001b[0m             flatten_emb\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflatten_emb,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=644'>645</a>\u001b[0m             embed_folder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_folder,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=645'>646</a>\u001b[0m             embed_layer\u001b[39m=\u001b[39;49membed_layer,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=646'>647</a>\u001b[0m             seq_start_idx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_start_idx,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=647'>648</a>\u001b[0m             seq_end_idx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_end_idx,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=648'>649</a>\u001b[0m             if_encode_all\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mif_encode_all,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=649'>650</a>\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_params,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=650'>651</a>\u001b[0m         )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=651'>652</a>\u001b[0m         \u001b[39mfor\u001b[39;00m subset \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=652'>653</a>\u001b[0m     ]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=653'>654</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbefore pick model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000011vscode-remote?line=654'>655</a>\u001b[0m \u001b[39m# train and get the best alpha\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/protein-transfer/scr/preprocess/data_process.py:363\u001b[0m, in \u001b[0;36mProtranDataset.__init__\u001b[0;34m(self, dataset_path, subset, encoder_name, reset_param, resample_param, embed_batch_size, flatten_emb, embed_folder, embed_layer, seq_start_idx, seq_end_idx, if_encode_all, **encoder_params)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39m# without such info\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(dataset_path)\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ds_info \u001b[39m=\u001b[39m DatasetInfo(dataset_path)\n\u001b[1;32m    364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ds_info\u001b[39m.\u001b[39mmodel_type\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numb_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ds_info\u001b[39m.\u001b[39mnumb_class\n",
      "File \u001b[0;32m~/repo/protein-transfer/scr/preprocess/data_process.py:161\u001b[0m, in \u001b[0;36mDatasetInfo.__init__\u001b[0;34m(self, dataset_path)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, dataset_path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m    - dataset_path: str, the path for the csv\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(dataset_path)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/pandas/io/parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 610\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/pandas/io/parsers.py:468\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    467\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 468\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/pandas/io/parsers.py:1057\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1056\u001b[0m     nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m-> 1057\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1059\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1060\u001b[0m         \u001b[39mif\u001b[39;00m col_dict:\n\u001b[1;32m   1061\u001b[0m             \u001b[39m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/pandas/io/parsers.py:2036\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2035\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2036\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   2037\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   2038\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:756\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:771\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:982\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:1028\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:1071\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/pandas/core/dtypes/common.py:537\u001b[0m, in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m IntervalDtype\u001b[39m.\u001b[39mis_dtype(arr_or_dtype)\n\u001b[0;32m--> 537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_categorical_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[39m    Check whether an array-like or dtype is of the Categorical dtype.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr_or_dtype, ExtensionDtype):\n\u001b[1;32m    565\u001b[0m         \u001b[39m# GH#33400 fastpath for dtype object\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RunSK(\n",
    "    dataset_path=\"data/proeng/thermo/mixed_split.csv\",\n",
    "    # encoder_name=\"esm1_t34_670M_UR50S\",\n",
    "    encoder_name=\"esm1_t6_43M_UR50S\",\n",
    "    # encoder_name=\"esm1_t12_85M_UR50S\",\n",
    "    # encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "    reset_param= False,\n",
    "    resample_param = False,\n",
    "    embed_batch_size = 128,\n",
    "    flatten_emb = \"mean\",\n",
    "    embed_folder = \"embeddings/proeng/thermo/mixed_split\",\n",
    "    all_embed_layers=False,\n",
    "    seq_start_idx = False,\n",
    "    seq_end_idx = False,\n",
    "    if_encode_all=False,\n",
    "    alphas = SKLEARN_ALPHAS,\n",
    "    sklearn_state= RAND_SEED,\n",
    "    # sklearn_params= {\"normalize\": True},\n",
    "    all_result_folder = \"test/sklearn\",\n",
    "    # **encoder_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"embeddings/proeng/thermo/mixed_split/esm1_t6_43M_UR50S/mean/train/embedding.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting classes into int...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting classes into int...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting classes into int...\n",
      "Running LinearClassifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [3],\n",
       "       [3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting embed for 0...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 0\n",
      "Converting classes into int...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 0\n",
      "Converting classes into int...\n",
      "Generating esm1_t6_43M_UR50S upto 6 layer embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attr for layer 0\n",
      "Converting classes into int...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m RunSK(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m     dataset_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/annotation/scl/balanced.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m# encoder_name=\"esm1_t34_670M_UR50S\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m     encoder_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mesm1_t6_43M_UR50S\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39m# encoder_name=\"esm1_t12_85M_UR50S\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39m# encoder_name=\"esm1b_t33_650M_UR50S\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m     reset_param\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=7'>8</a>\u001b[0m     resample_param \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m     embed_batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m     flatten_emb \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=10'>11</a>\u001b[0m     embed_folder \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39membeddings/annotation/scl/balanced\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=11'>12</a>\u001b[0m     all_embed_layers\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=12'>13</a>\u001b[0m     seq_start_idx \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=13'>14</a>\u001b[0m     seq_end_idx \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=14'>15</a>\u001b[0m     if_encode_all\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=15'>16</a>\u001b[0m     alphas \u001b[39m=\u001b[39;49m SKLEARN_ALPHAS,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m     sklearn_state\u001b[39m=\u001b[39;49m RAND_SEED,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m     \u001b[39m# sklearn_params= {\"normalize\": True},\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=18'>19</a>\u001b[0m     all_result_folder \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtest/sklearn\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m     \u001b[39m# **encoder_params,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m )\n",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 8\u001b[0m in \u001b[0;36mRunSK.__init__\u001b[0;34m(self, dataset_path, encoder_name, reset_param, resample_param, embed_batch_size, flatten_emb, embed_folder, all_embed_layers, seq_start_idx, seq_end_idx, if_encode_all, alphas, sklearn_state, sklearn_params, all_result_folder, **encoder_params)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=469'>470</a>\u001b[0m all_sklearn_results \u001b[39m=\u001b[39m {}\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=471'>472</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(total_emb_layer):\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=472'>473</a>\u001b[0m     all_sklearn_results[layer] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_sklearn_layer(embed_layer\u001b[39m=\u001b[39;49mlayer,)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=474'>475</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_all_sklearn_results \u001b[39m=\u001b[39m all_sklearn_results\n",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 8\u001b[0m in \u001b[0;36mRunSK.run_sklearn_layer\u001b[0;34m(self, embed_layer)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=633'>634</a>\u001b[0m     ds_list \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=634'>635</a>\u001b[0m         ProtranDataset(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=635'>636</a>\u001b[0m             dataset_path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=649'>650</a>\u001b[0m         \u001b[39mfor\u001b[39;00m subset \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=650'>651</a>\u001b[0m     ]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=652'>653</a>\u001b[0m \u001b[39m# train and get the best alpha\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=653'>654</a>\u001b[0m best_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpick_model(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=654'>655</a>\u001b[0m     embed_layer\u001b[39m=\u001b[39;49membed_layer, train_ds\u001b[39m=\u001b[39;49mds_list[\u001b[39m0\u001b[39;49m], val_ds\u001b[39m=\u001b[39;49mds_list[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=655'>656</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=657'>658</a>\u001b[0m \u001b[39m# init dict for resulted outputs\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=658'>659</a>\u001b[0m result_dict \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb Cell 8\u001b[0m in \u001b[0;36mRunSK.pick_model\u001b[0;34m(self, embed_layer, train_ds, val_ds)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=558'>559</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=559'>560</a>\u001b[0m     y \u001b[39m=\u001b[39m train_ds\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mravel()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=561'>562</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\u001b[39mgetattr\u001b[39;49m(train_ds, \u001b[39m\"\u001b[39;49m\u001b[39mlayer\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(embed_layer)), y)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=563'>564</a>\u001b[0m \u001b[39m# eval the model with train and test\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=564'>565</a>\u001b[0m train_pred, train_true, train_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msk_test(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=565'>566</a>\u001b[0m     model, train_ds, embed_layer\u001b[39m=\u001b[39membed_layer\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgcrazgdl2369/home/t-fli/repo/protein-transfer/sandbox/sklearn_fromemb.ipynb#ch0000004vscode-remote?line=566'>567</a>\u001b[0m )\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1406\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1406\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1407\u001b[0m                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer))(\n\u001b[1;32m   1408\u001b[0m     path_func(X, y, pos_class\u001b[39m=\u001b[39;49mclass_, Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1409\u001b[0m               l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio, fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1410\u001b[0m               tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1411\u001b[0m               multi_class\u001b[39m=\u001b[39;49mmulti_class, max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1412\u001b[0m               class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1413\u001b[0m               random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state, coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1414\u001b[0m               penalty\u001b[39m=\u001b[39;49mpenalty, max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1415\u001b[0m               sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m   1416\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef))\n\u001b[1;32m   1418\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/utils/fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 222\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:758\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    756\u001b[0m     iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    757\u001b[0m         np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)]\n\u001b[0;32m--> 758\u001b[0m     opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    759\u001b[0m         func, w0, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m, jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    760\u001b[0m         args\u001b[39m=\u001b[39;49m(X, target, \u001b[39m1.\u001b[39;49m \u001b[39m/\u001b[39;49m C, sample_weight),\n\u001b[1;32m    761\u001b[0m         options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter}\n\u001b[1;32m    762\u001b[0m     )\n\u001b[1;32m    763\u001b[0m     n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    764\u001b[0m         solver, opt_res, max_iter,\n\u001b[1;32m    765\u001b[0m         extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n\u001b[1;32m    766\u001b[0m     w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/scipy/optimize/_minimize.py:619\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    617\u001b[0m                               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    618\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    620\u001b[0m                             callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    621\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    622\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    623\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/anaconda/envs/protran/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py:351\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    347\u001b[0m n_iterations \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    349\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39m1\u001b[39m:\n\u001b[1;32m    350\u001b[0m     \u001b[39m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     _lbfgsb\u001b[39m.\u001b[39;49msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[1;32m    352\u001b[0m                    pgtol, wa, iwa, task, iprint, csave, lsave,\n\u001b[1;32m    353\u001b[0m                    isave, dsave, maxls)\n\u001b[1;32m    354\u001b[0m     task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    356\u001b[0m         \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m         \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    358\u001b[0m         \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m         \u001b[39m# Overwrite f and g:\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RunSK(\n",
    "    dataset_path=\"data/annotation/scl/balanced.csv\",\n",
    "    # encoder_name=\"esm1_t34_670M_UR50S\",\n",
    "    encoder_name=\"esm1_t6_43M_UR50S\",\n",
    "    # encoder_name=\"esm1_t12_85M_UR50S\",\n",
    "    # encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "    reset_param= False,\n",
    "    resample_param = False,\n",
    "    embed_batch_size = 128,\n",
    "    flatten_emb = \"mean\",\n",
    "    embed_folder = \"embeddings/annotation/scl/balanced\",\n",
    "    all_embed_layers=False,\n",
    "    seq_start_idx = False,\n",
    "    seq_end_idx = False,\n",
    "    if_encode_all=False,\n",
    "    alphas = SKLEARN_ALPHAS,\n",
    "    sklearn_state= RAND_SEED,\n",
    "    # sklearn_params= {\"normalize\": True},\n",
    "    all_result_folder = \"test/sklearn\",\n",
    "    # **encoder_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': 'True'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"normalize\": \"True\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [10]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"a\":[10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads('{\"normalize\":true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normalize': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.dumps({\"normalize\": True}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
