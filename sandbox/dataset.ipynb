{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.preprocess.data_process import TaskProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>csv_path</th>\n",
       "      <th>fasta_path</th>\n",
       "      <th>pkl_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>annotation</td>\n",
       "      <td>scl</td>\n",
       "      <td>balanced</td>\n",
       "      <td>data/annotation/scl/balanced.csv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>structure</td>\n",
       "      <td>secondary_structure</td>\n",
       "      <td>cb513</td>\n",
       "      <td>[data/structure/secondary_structure/secondary_...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proeng</td>\n",
       "      <td>gb1</td>\n",
       "      <td>two_vs_rest</td>\n",
       "      <td>data/proeng/gb1/two_vs_rest.csv</td>\n",
       "      <td>data/proeng/gb1/5LDE_1.fasta</td>\n",
       "      <td>data/proeng/gb1/two_vs_rest.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proeng</td>\n",
       "      <td>gb1</td>\n",
       "      <td>low_vs_high</td>\n",
       "      <td>data/proeng/gb1/low_vs_high.csv</td>\n",
       "      <td>data/proeng/gb1/5LDE_1.fasta</td>\n",
       "      <td>data/proeng/gb1/low_vs_high.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proeng</td>\n",
       "      <td>aav</td>\n",
       "      <td>one_vs_many</td>\n",
       "      <td>data/proeng/aav/one_vs_many.csv</td>\n",
       "      <td>data/proeng/aav/P03135.fasta</td>\n",
       "      <td>data/proeng/aav/one_vs_many.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>proeng</td>\n",
       "      <td>aav</td>\n",
       "      <td>two_vs_many</td>\n",
       "      <td>data/proeng/aav/two_vs_many.csv</td>\n",
       "      <td>data/proeng/aav/P03135.fasta</td>\n",
       "      <td>data/proeng/aav/two_vs_many.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>proeng</td>\n",
       "      <td>thermo</td>\n",
       "      <td>mixed</td>\n",
       "      <td>data/proeng/thermo/mixed.csv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task              dataset        split  \\\n",
       "0  annotation                  scl     balanced   \n",
       "1   structure  secondary_structure        cb513   \n",
       "2      proeng                  gb1  two_vs_rest   \n",
       "3      proeng                  gb1  low_vs_high   \n",
       "4      proeng                  aav  one_vs_many   \n",
       "5      proeng                  aav  two_vs_many   \n",
       "6      proeng               thermo        mixed   \n",
       "\n",
       "                                            csv_path  \\\n",
       "0                   data/annotation/scl/balanced.csv   \n",
       "1  [data/structure/secondary_structure/secondary_...   \n",
       "2                    data/proeng/gb1/two_vs_rest.csv   \n",
       "3                    data/proeng/gb1/low_vs_high.csv   \n",
       "4                    data/proeng/aav/one_vs_many.csv   \n",
       "5                    data/proeng/aav/two_vs_many.csv   \n",
       "6                       data/proeng/thermo/mixed.csv   \n",
       "\n",
       "                     fasta_path                         pkl_path  \n",
       "0                                                                 \n",
       "1                                                                 \n",
       "2  data/proeng/gb1/5LDE_1.fasta  data/proeng/gb1/two_vs_rest.pkl  \n",
       "3  data/proeng/gb1/5LDE_1.fasta  data/proeng/gb1/low_vs_high.pkl  \n",
       "4  data/proeng/aav/P03135.fasta  data/proeng/aav/one_vs_many.pkl  \n",
       "5  data/proeng/aav/P03135.fasta  data/proeng/aav/two_vs_many.pkl  \n",
       "6                                                                 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskProcess().sum_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.preprocess.data_process import ProtranDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.encoding.encoding_classes import ESMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ESMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading esm1b_t33_650M_UR50S using 0 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 2/2 [00:32<00:00, 16.47s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_path=\"data/proeng/gb1/two_vs_rest.pkl\"\n",
    "val_dataset = ProtranDataset(dataset_path=dataset_path, \n",
    "                             subset=\"val\",\n",
    "                             encoder_class=ESMEncoder,\n",
    "                             encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "                             embed_layer=0,\n",
    "                             embed_batch_size=32,\n",
    "                             flatten_emb=\"mean\",\n",
    "                             embed_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,\n",
       " (tensor([-0.1774, -0.0007,  0.0167,  ...,  0.0066,  0.0361,  0.0965]),\n",
       "  1.80292279874,\n",
       "  'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVNGEWTYDDATKTFTVTELEVLFQGPLDPNSMATYEVLCEVARKLGTDDREVVLFLLNVFIPQPTLAQLIGALRALKEEGRLTFPLLAECLFRAGRRDLLRDLLHLDPRFLERHLAGTMSYFSPYQLTVLHVDGELCARDIRSLIFLSKDTIGSRSTPQTFLHWVYCMENLDLLGPTDVDALMSMLRSLSRVDLQRQVQTLMGLHLSGPSHSQHYRHTPLEHHHHHH',\n",
       "  'D40N',\n",
       "  1),\n",
       " torch.Size([1280]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset), val_dataset[0], val_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "            dataset=val_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            worker_init_fn=42,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1774, -0.0007,  0.0167,  ...,  0.0066,  0.0361,  0.0965],\n",
      "        [-0.1748, -0.0007,  0.0166,  ...,  0.0063,  0.0378,  0.0964],\n",
      "        [-0.1749, -0.0006,  0.0168,  ...,  0.0066,  0.0395,  0.0966],\n",
      "        ...,\n",
      "        [-0.1766, -0.0007,  0.0166,  ...,  0.0063,  0.0361,  0.0966],\n",
      "        [-0.1775, -0.0007,  0.0165,  ...,  0.0063,  0.0366,  0.0968],\n",
      "        [-0.1771,  0.0002,  0.0165,  ...,  0.0065,  0.0362,  0.0964]]) tensor([1.8029e+00, 7.1123e-01, 8.6005e-01, 6.1898e-01, 2.2602e+00, 1.7291e+00,\n",
      "        1.7197e+00, 2.2677e+00, 1.7626e+00, 2.3160e-01, 6.1434e-01, 6.1031e-01,\n",
      "        1.0339e+00, 5.1069e-01, 6.9899e-01, 1.8930e+00, 0.0000e+00, 6.9803e-01,\n",
      "        5.9696e-01, 1.1877e+00, 9.7038e-01, 5.5813e-01, 4.1580e+00, 8.5351e-01,\n",
      "        6.0882e-01, 1.0669e+00, 1.7081e+00, 3.0943e+00, 2.9738e-03, 7.3959e-02,\n",
      "        1.9298e+00, 1.9539e+00], dtype=torch.float64)\n",
      "tensor([[-0.1768, -0.0007,  0.0165,  ...,  0.0065,  0.0366,  0.0965],\n",
      "        [-0.1752, -0.0007,  0.0166,  ...,  0.0065,  0.0366,  0.0967],\n",
      "        [-0.1753,  0.0002,  0.0166,  ...,  0.0065,  0.0361,  0.0970],\n",
      "        ...,\n",
      "        [-0.1770, -0.0006,  0.0167,  ...,  0.0062,  0.0367,  0.0968],\n",
      "        [-0.1758,  0.0003,  0.0166,  ...,  0.0063,  0.0364,  0.0963],\n",
      "        [-0.1779, -0.0006,  0.0169,  ...,  0.0062,  0.0366,  0.0962]]) tensor([0.6206, 0.7048, 1.1327, 0.1557, 1.9346, 1.2409, 0.9932, 1.4394, 2.0135,\n",
      "        4.0264, 1.2880], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for (x, y, sequence, mut_name, mut_numb) in val_loader:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 1280]), torch.Size([11]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVIGEWTYDDATKTFTGTE',\n",
       " 'V',\n",
       " 'I',\n",
       " 'G',\n",
       " 'G')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[0][:56], sequence[0][38],  sequence[0][39], sequence[0][40], sequence[0][53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D40I:V54G', tensor(2))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mut_name[0], mut_numb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56\n",
      "Loading esm1b_t33_650M_UR50S using 0 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_path=\"data/proeng/gb1/two_vs_rest.pkl\"\n",
    "val_dataset = ProtranDataset(dataset_path=dataset_path, \n",
    "                             subset=\"val\",\n",
    "                             encoder_class=ESMEncoder,\n",
    "                             encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "                             embed_layer=0,\n",
    "                             embed_batch_size=32,\n",
    "                             flatten_emb=\"mean\",\n",
    "                             embed_path=None,\n",
    "                             seq_start_idx = False,\n",
    "                             seq_end_idx = 56,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,\n",
       " (tensor([-0.1717, -0.0072,  0.0006,  ...,  0.0170, -0.0106,  0.1181]),\n",
       "  array([1.8029228]),\n",
       "  'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVNGEWTYDDATKTFTVTE',\n",
       "  'D40N',\n",
       "  1),\n",
       " torch.Size([1280]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset), val_dataset[0], val_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1\n",
      "Loading esm1b_t33_650M_UR50S using 0 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 2/2 [00:29<00:00, 14.74s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_path=\"data/proeng/gb1/two_vs_rest.pkl\"\n",
    "val_dataset = ProtranDataset(dataset_path=dataset_path, \n",
    "                             subset=\"val\",\n",
    "                             encoder_class=ESMEncoder,\n",
    "                             encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "                             embed_layer=0,\n",
    "                             embed_batch_size=32,\n",
    "                             flatten_emb=\"mean\",\n",
    "                             embed_path=None,\n",
    "                             seq_start_idx = False,\n",
    "                             seq_end_idx = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,\n",
       " (tensor([-0.1778, -0.0008,  0.0162,  ...,  0.0069,  0.0351,  0.0969]),\n",
       "  array([1.8029228]),\n",
       "  'MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVNGEWTYDDATKTFTVTELEVLFQGPLDPNSMATYEVLCEVARKLGTDDREVVLFLLNVFIPQPTLAQLIGALRALKEEGRLTFPLLAECLFRAGRRDLLRDLLHLDPRFLERHLAGTMSYFSPYQLTVLHVDGELCARDIRSLIFLSKDTIGSRSTPQTFLHWVYCMENLDLLGPTDVDALMSMLRSLSRVDLQRQVQTLMGLHLSGPSHSQHYRHTPLEHHHHH',\n",
       "  'D40N',\n",
       "  1),\n",
       " torch.Size([1280]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset), val_dataset[0], val_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.params.train_test import *\n",
    "from scr.model.pytorch_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "  (linear): Linear(in_features=1280, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(input_dim=1280, output_dim=1)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "criterion.to(DEVICE, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56\n",
      "Loading esm1b_t33_650M_UR50S using 0 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 12/12 [00:51<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=ProtranDataset(dataset_path=dataset_path, \n",
    "                             subset=\"train\",\n",
    "                             encoder_class=ESMEncoder,\n",
    "                             encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "                             embed_layer=0,\n",
    "                             embed_batch_size=32,\n",
    "                             flatten_emb=\"mean\",\n",
    "                             embed_path=None,\n",
    "                             seq_start_idx = False,\n",
    "                             seq_end_idx = 56,),\n",
    "                             batch_size=64,\n",
    "                             shuffle=True,\n",
    "                             worker_init_fn=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 1.8848106861114502\n",
      "train epoch: 1, loss: 0.8859107494354248\n",
      "train epoch: 2, loss: 0.7485132217407227\n",
      "train epoch: 3, loss: 1.1097514629364014\n",
      "train epoch: 4, loss: 1.180535912513733\n",
      "train epoch: 5, loss: 0.9715085029602051\n",
      "train epoch: 6, loss: 1.5346686840057373\n",
      "train epoch: 7, loss: 1.1948903799057007\n",
      "train epoch: 8, loss: 1.3356726169586182\n",
      "train epoch: 9, loss: 0.8179222941398621\n",
      "train epoch: 10, loss: 1.529645323753357\n",
      "train epoch: 11, loss: 0.9965928792953491\n",
      "train epoch: 12, loss: 1.1581487655639648\n",
      "train epoch: 13, loss: 0.9006614685058594\n",
      "train epoch: 14, loss: 1.0335042476654053\n",
      "train epoch: 15, loss: 0.9751642346382141\n",
      "train epoch: 16, loss: 0.7143483757972717\n",
      "train epoch: 17, loss: 1.5195609331130981\n",
      "train epoch: 18, loss: 1.1130298376083374\n",
      "train epoch: 19, loss: 1.1967966556549072\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(20):\n",
    "    for (x, y, sequence, mut_name, mut_numb) in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss = criterion(out, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'train epoch: {epoch}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 43)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset), len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56\n",
      "Loading esm1b_t33_650M_UR50S using 33 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 12/12 [00:53<00:00,  4.43s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=ProtranDataset(dataset_path=dataset_path, \n",
    "                             subset=\"train\",\n",
    "                             encoder_class=ESMEncoder,\n",
    "                             encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "                             embed_layer=33,\n",
    "                             embed_batch_size=32,\n",
    "                             flatten_emb=\"mean\",\n",
    "                             embed_path=None,\n",
    "                             seq_start_idx = False,\n",
    "                             seq_end_idx = 56,),\n",
    "                             batch_size=64,\n",
    "                             shuffle=True,\n",
    "                             worker_init_fn=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 1.0062204599380493\n",
      "train epoch: 1, loss: 0.860078752040863\n",
      "train epoch: 2, loss: 0.626774787902832\n",
      "train epoch: 3, loss: 1.0024996995925903\n",
      "train epoch: 4, loss: 1.1956404447555542\n",
      "train epoch: 5, loss: 0.903653085231781\n",
      "train epoch: 6, loss: 1.43190336227417\n",
      "train epoch: 7, loss: 1.1046732664108276\n",
      "train epoch: 8, loss: 1.2266196012496948\n",
      "train epoch: 9, loss: 0.7690103650093079\n",
      "train epoch: 10, loss: 1.4974141120910645\n",
      "train epoch: 11, loss: 0.9335665106773376\n",
      "train epoch: 12, loss: 1.0518162250518799\n",
      "train epoch: 13, loss: 0.8178434371948242\n",
      "train epoch: 14, loss: 0.946225106716156\n",
      "train epoch: 15, loss: 0.9004098773002625\n",
      "train epoch: 16, loss: 0.6763227581977844\n",
      "train epoch: 17, loss: 1.3393670320510864\n",
      "train epoch: 18, loss: 0.9797210097312927\n",
      "train epoch: 19, loss: 1.0611830949783325\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(20):\n",
    "    for (x, y, sequence, mut_name, mut_numb) in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss = criterion(out, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'train epoch: {epoch}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
