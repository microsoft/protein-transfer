{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    }
   ],
   "source": [
    "model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm1b_t33_650M_UR50S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 1280)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_emb = model.embed_tokens.weight.detach().cpu().numpy()\n",
    "aa_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.0032, 0.0592, 0.0474,  ..., 0.0142, 0.0754, 0.0690],\n",
       "        requires_grad=True),\n",
       " torch.Size([1280]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_weights = list(model.parameters())[-1]\n",
    "last_weights, last_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 1280])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0663, -0.0206,  0.0212,  ...,  0.0336,  0.3534,  0.3684],\n",
      "         [ 0.2793, -0.0092,  0.0531,  ...,  0.0053, -0.0854,  0.2145],\n",
      "         [ 0.8682,  0.0139, -0.0363,  ..., -0.0775, -0.0688,  0.1010],\n",
      "         ...,\n",
      "         [-0.1451,  0.0310, -0.0578,  ..., -0.1140, -0.0157,  0.2026],\n",
      "         [-0.0656, -0.0076, -0.0974,  ...,  0.0546,  0.0260,  0.2645],\n",
      "         [-0.2940, -0.0431,  0.0488,  ...,  0.0070,  0.0056,  0.2847]]]) torch.Size([1, 58, 1280]) [tensor([-0.1665, -0.0073,  0.0005,  ...,  0.0174,  0.0038,  0.1164])] 1280\n"
     ]
    }
   ],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"2gi9\", \"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[0], return_contacts=False)\n",
    "token_representations = results[\"representations\"][0]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n",
    "\n",
    "print(token_representations, token_representations.shape, sequence_representations, len(sequence_representations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0454,  0.2249,  0.1654,  ...,  0.0380,  0.0451, -0.0621],\n",
      "         [-0.0642, -0.2746,  0.4808,  ..., -0.0545, -0.1764,  0.0235],\n",
      "         [-0.1702,  0.0312, -0.2013,  ..., -0.0612, -0.2743,  0.3677],\n",
      "         ...,\n",
      "         [-0.0621,  0.2908,  0.6940,  ..., -0.2058, -0.0074,  0.4298],\n",
      "         [-0.1076,  0.1801,  0.1223,  ..., -0.1654,  0.0073,  0.0412],\n",
      "         [-0.0576, -0.0605,  0.0807,  ..., -0.0661,  0.1188,  0.1108]]]) torch.Size([1, 58, 1280]) [tensor([-0.0211,  0.1367, -0.0039,  ..., -0.0647, -0.0582,  0.1644])] 1280\n"
     ]
    }
   ],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"2gi9\", \"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "token_representations = results[\"representations\"][33]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n",
    "\n",
    "print(token_representations, token_representations.shape, sequence_representations, len(sequence_representations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 58, 1280])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"representations\"][33].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logits', 'representations', 'attentions', 'contacts'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([33])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"representations\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
