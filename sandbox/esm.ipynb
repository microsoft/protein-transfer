{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.preprocess.data_process import TaskProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>csv_path</th>\n",
       "      <th>fasta_path</th>\n",
       "      <th>pkl_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>annotation</td>\n",
       "      <td>scl</td>\n",
       "      <td>balanced</td>\n",
       "      <td>data/annotation/scl/balanced.csv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>structure</td>\n",
       "      <td>secondary_structure</td>\n",
       "      <td>cb513</td>\n",
       "      <td>[data/structure/secondary_structure/secondary_...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proeng</td>\n",
       "      <td>gb1</td>\n",
       "      <td>two_vs_rest</td>\n",
       "      <td>data/proeng/gb1/two_vs_rest.csv</td>\n",
       "      <td>data/proeng/gb1/5LDE_1.fasta</td>\n",
       "      <td>data/proeng/gb1/two_vs_rest.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proeng</td>\n",
       "      <td>gb1</td>\n",
       "      <td>low_vs_high</td>\n",
       "      <td>data/proeng/gb1/low_vs_high.csv</td>\n",
       "      <td>data/proeng/gb1/5LDE_1.fasta</td>\n",
       "      <td>data/proeng/gb1/low_vs_high.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proeng</td>\n",
       "      <td>aav</td>\n",
       "      <td>one_vs_many</td>\n",
       "      <td>data/proeng/aav/one_vs_many.csv</td>\n",
       "      <td>data/proeng/aav/P03135.fasta</td>\n",
       "      <td>data/proeng/aav/one_vs_many.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>proeng</td>\n",
       "      <td>aav</td>\n",
       "      <td>two_vs_many</td>\n",
       "      <td>data/proeng/aav/two_vs_many.csv</td>\n",
       "      <td>data/proeng/aav/P03135.fasta</td>\n",
       "      <td>data/proeng/aav/two_vs_many.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>proeng</td>\n",
       "      <td>thermo</td>\n",
       "      <td>mixed</td>\n",
       "      <td>data/proeng/thermo/mixed.csv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         task              dataset        split  \\\n",
       "0  annotation                  scl     balanced   \n",
       "1   structure  secondary_structure        cb513   \n",
       "2      proeng                  gb1  two_vs_rest   \n",
       "3      proeng                  gb1  low_vs_high   \n",
       "4      proeng                  aav  one_vs_many   \n",
       "5      proeng                  aav  two_vs_many   \n",
       "6      proeng               thermo        mixed   \n",
       "\n",
       "                                            csv_path  \\\n",
       "0                   data/annotation/scl/balanced.csv   \n",
       "1  [data/structure/secondary_structure/secondary_...   \n",
       "2                    data/proeng/gb1/two_vs_rest.csv   \n",
       "3                    data/proeng/gb1/low_vs_high.csv   \n",
       "4                    data/proeng/aav/one_vs_many.csv   \n",
       "5                    data/proeng/aav/two_vs_many.csv   \n",
       "6                       data/proeng/thermo/mixed.csv   \n",
       "\n",
       "                     fasta_path                         pkl_path  \n",
       "0                                                                 \n",
       "1                                                                 \n",
       "2  data/proeng/gb1/5LDE_1.fasta  data/proeng/gb1/two_vs_rest.pkl  \n",
       "3  data/proeng/gb1/5LDE_1.fasta  data/proeng/gb1/low_vs_high.pkl  \n",
       "4  data/proeng/aav/P03135.fasta  data/proeng/aav/one_vs_many.pkl  \n",
       "5  data/proeng/aav/P03135.fasta  data/proeng/aav/two_vs_many.pkl  \n",
       "6                                                                 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskProcess().sum_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    }
   ],
   "source": [
    "model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm1b_t33_650M_UR50S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = lmdb.open(str(\"data/structure/secondary_structure/secondary_structure_train.lmdb\"), max_readers=1, readonly=True, lock=False, readahead=False, meminit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with env.begin(write=False) as txn:\n",
    "    num_examples = pkl.loads(txn.get(b'num_examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8678"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with env.begin(write=False) as txn:\n",
    "    item = pkl.loads(txn.get(str(0).encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['asa_max', 'disorder', 'evolutionary', 'interface', 'phi', 'primary', 'psi', 'rsa', 'ss3', 'ss8', 'valid_mask', 'id', 'protein_length'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4580, 509, 3644, 8733)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[(df[\"set\"] == \"train\") & (df[\"validation\"] != True)]\n",
    "df_val = df.loc[(df[\"set\"] == \"train\") & (df[\"validation\"] == True)]\n",
    "df_test = df.loc[(df[\"set\"] == \"test\")]\n",
    "\n",
    "len(df_train), len(df_val), len(df_test), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(zip(df_val.sequence, df_val.Code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 1280])\n",
      "tensor([[[-0.0663, -0.0206,  0.0212,  ...,  0.0336,  0.3534,  0.3684],\n",
      "         [ 0.2793, -0.0092,  0.0531,  ...,  0.0053, -0.0854,  0.2145],\n",
      "         [ 0.8682,  0.0139, -0.0363,  ..., -0.0775, -0.0688,  0.1010],\n",
      "         ...,\n",
      "         [-0.1451,  0.0310, -0.0578,  ..., -0.1140, -0.0157,  0.2026],\n",
      "         [-0.0656, -0.0076, -0.0974,  ...,  0.0546,  0.0260,  0.2645],\n",
      "         [-0.2940, -0.0431,  0.0488,  ...,  0.0070,  0.0056,  0.2847]]]) torch.Size([1, 58, 1280]) [tensor([-0.1665, -0.0073,  0.0005,  ...,  0.0174,  0.0038,  0.1164])] 1280\n"
     ]
    }
   ],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"2gi9\", \"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[0], return_contacts=False)\n",
    "token_representations = results[\"representations\"][0]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    print(token_representations[i, 1 : len(seq) + 1].shape)\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n",
    "\n",
    "print(token_representations, token_representations.shape, sequence_representations, len(sequence_representations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 1280])\n",
      "tensor([[[-0.0663, -0.0206,  0.0212,  ...,  0.0336,  0.3534,  0.3684],\n",
      "         [ 0.2793, -0.0092,  0.0531,  ...,  0.0053, -0.0854,  0.2145],\n",
      "         [ 0.8682,  0.0139, -0.0363,  ..., -0.0775, -0.0688,  0.1010],\n",
      "         ...,\n",
      "         [-0.1451,  0.0310, -0.0578,  ..., -0.1140, -0.0157,  0.2026],\n",
      "         [-0.0656, -0.0076, -0.0974,  ...,  0.0546,  0.0260,  0.2645],\n",
      "         [-0.2940, -0.0431,  0.0488,  ...,  0.0070,  0.0056,  0.2847]]]) torch.Size([1, 58, 1280]) [tensor([-0.1665, -0.0073,  0.0005,  ...,  0.0174,  0.0038,  0.1164])] 1280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[0], return_contacts=False)\n",
    "token_representations = results[\"representations\"][0]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    print(token_representations[i, 1 : len(seq) + 1].shape)\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n",
    "\n",
    "print(token_representations, token_representations.shape, sequence_representations, len(sequence_representations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.encoding.encoding_classes import ESMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM model: esm1b_t33_650M_UR50S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embedding flattening\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.27928993, -0.00919111,  0.05307703, ...,  0.0052783 ,\n",
       "         -0.08536895,  0.2144556 ],\n",
       "        [ 0.86820096,  0.01390768, -0.03625386, ..., -0.07747608,\n",
       "         -0.06879894,  0.10098855],\n",
       "        [ 0.9904541 ,  0.02066673,  0.04346693, ..., -0.04951385,\n",
       "          0.04328922, -0.09477672],\n",
       "        ...,\n",
       "        [ 0.07968199, -0.01003133, -0.02964539, ...,  0.00346076,\n",
       "         -0.45212165,  0.23354846],\n",
       "        [-0.14514625,  0.03099104, -0.05777264, ..., -0.11398804,\n",
       "         -0.01572975,  0.20261148],\n",
       "        [-0.06561151, -0.00760958, -0.09738796, ...,  0.05461294,\n",
       "          0.02598158,  0.26446784]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ESMEncoder(\n",
    "    esm_model_name=\"esm1b_t33_650M_UR50S\",\n",
    "    esm_emb_layer=0,\n",
    "    fasta_loc=\"\",\n",
    "    fasta_seq=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",\n",
    ").encode(mut_seqs=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM model: esm1b_t33_650M_UR50S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.16647258, -0.00734616,  0.00054652, ...,  0.01738006,\n",
       "         0.00381861,  0.11643288]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ESMEncoder(\n",
    "    esm_model_name=\"esm1b_t33_650M_UR50S\",\n",
    "    esm_emb_layer=0,\n",
    "    fasta_loc=\"\",\n",
    "    fasta_seq=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",\n",
    ").encode(mut_seqs=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",flatten_emb=\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56, 1280])\n",
      "tensor([[[-0.3899,  0.1210, -0.7449,  ..., -0.9544,  0.4704,  0.6206],\n",
      "         [ 0.4447,  0.8576,  0.1733,  ..., -0.8428,  0.4788,  0.9012],\n",
      "         [ 1.3972,  1.1721, -0.5245,  ..., -1.4560,  0.0084,  0.3406],\n",
      "         ...,\n",
      "         [ 0.4156,  0.8773,  0.4632,  ..., -0.9489, -0.3087,  1.6864],\n",
      "         [ 0.7929,  0.9090, -0.9665,  ..., -0.6917,  0.5742,  0.9072],\n",
      "         [-0.0441,  0.6803, -0.3759,  ..., -0.3495,  0.1413,  0.8631]]]) torch.Size([1, 58, 1280]) [tensor([ 0.1365,  0.7353, -0.1419,  ..., -0.5605,  0.1081,  0.6370])] 1280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[1], return_contacts=False)\n",
    "token_representations = results[\"representations\"][1]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    print(token_representations[i, 1 : len(seq) + 1].shape)\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n",
    "\n",
    "print(token_representations, token_representations.shape, sequence_representations, len(sequence_representations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM model: esm1b_t33_650M_UR50S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.13647312,  0.7353482 , -0.14194234, ..., -0.5604886 ,\n",
       "         0.10806996,  0.6370432 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ESMEncoder(\n",
    "    esm_model_name=\"esm1b_t33_650M_UR50S\",\n",
    "    esm_emb_layer=1,\n",
    "    fasta_loc=\"\",\n",
    "    fasta_seq=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",\n",
    ").encode(mut_seqs=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",flatten_emb=\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33])\n",
      "tensor([[[-0.3899,  0.1210, -0.7449,  ..., -0.9544,  0.4704,  0.6206],\n",
      "         [ 0.4447,  0.8576,  0.1733,  ..., -0.8428,  0.4788,  0.9012],\n",
      "         [ 1.3972,  1.1721, -0.5245,  ..., -1.4560,  0.0084,  0.3406],\n",
      "         ...,\n",
      "         [ 0.4156,  0.8773,  0.4632,  ..., -0.9489, -0.3087,  1.6864],\n",
      "         [ 0.7929,  0.9090, -0.9665,  ..., -0.6917,  0.5742,  0.9072],\n",
      "         [-0.0441,  0.6803, -0.3759,  ..., -0.3495,  0.1413,  0.8631]]])\n"
     ]
    }
   ],
   "source": [
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=list(range(0, 33+1)), return_contacts=False)\n",
    "print(results[\"representations\"].keys())\n",
    "token_representations = results[\"representations\"][1]\n",
    "print(token_representations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0454,  0.2249,  0.1654,  ...,  0.0380,  0.0451, -0.0621],\n",
      "         [-0.0642, -0.2746,  0.4808,  ..., -0.0545, -0.1764,  0.0235],\n",
      "         [-0.1702,  0.0312, -0.2013,  ..., -0.0612, -0.2743,  0.3677],\n",
      "         ...,\n",
      "         [-0.0621,  0.2908,  0.6940,  ..., -0.2058, -0.0074,  0.4298],\n",
      "         [-0.1076,  0.1801,  0.1223,  ..., -0.1654,  0.0073,  0.0412],\n",
      "         [-0.0576, -0.0605,  0.0807,  ..., -0.0661,  0.1188,  0.1108]]]) torch.Size([1, 58, 1280]) [tensor([-0.0211,  0.1367, -0.0039,  ..., -0.0647, -0.0582,  0.1644])] 1280\n"
     ]
    }
   ],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"2gi9\", \"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\"),\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "token_representations = results[\"representations\"][33]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, (_, seq) in enumerate(data):\n",
    "    sequence_representations.append(token_representations[i, 1 : len(seq) + 1].mean(0))\n",
    "\n",
    "print(token_representations, token_representations.shape, sequence_representations, len(sequence_representations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM model: esm1b_t33_650M_UR50S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02112344,  0.1367362 , -0.00392063, ..., -0.06472861,\n",
       "        -0.0582489 ,  0.16439287]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(ESMEncoder(\n",
    "    esm_model_name=\"esm1b_t33_650M_UR50S\",\n",
    "    esm_emb_layer=33,\n",
    "    fasta_loc=\"\",\n",
    "    fasta_seq=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",\n",
    ").encode(mut_seqs=\"MQYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDATKTFTVTE\",flatten_emb=\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
