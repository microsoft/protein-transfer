{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.preprocess.data_process import ProtranDataset\n",
    "from scr.encoding.encoding_classes import ESMEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.params.train_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.model.pytorch_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ESMEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(input_dim=1280, output_dim=1)\n",
    "model.to(DEVICE)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "criterion.to(DEVICE, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=\"data/proeng/gb1/two_vs_rest.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[True if subset == \"train\" else False for subset in [\"test\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_loader(\n",
    "    dataset_path: str,\n",
    "    subset_list: list[str] = [\"train\", \"val\"],\n",
    "    encoder_class=ESMEncoder,\n",
    "    encoder_name=\"esm1b_t33_650M_UR50S\",\n",
    "    embed_layer=0,\n",
    "    embed_batch_size=32,\n",
    "    flatten_emb=\"mean\",\n",
    "    embed_path=None,\n",
    "    seq_start_idx = False,\n",
    "    seq_end_idx = False,\n",
    "    loader_batch_size=32,\n",
    "    worker_seed=42,\n",
    "    **encoder_params\n",
    "):\n",
    "\n",
    "    if_shuffle_list = [True if subset == \"train\" else False for subset in subset_list]\n",
    "\n",
    "    return (\n",
    "        DataLoader(\n",
    "            dataset=ProtranDataset(\n",
    "                dataset_path=dataset_path,\n",
    "                subset=subset,\n",
    "                encoder_class=encoder_class,\n",
    "                encoder_name=encoder_name,\n",
    "                embed_layer=embed_layer,\n",
    "                embed_batch_size=embed_batch_size,\n",
    "                flatten_emb=flatten_emb,\n",
    "                embed_path=embed_path,\n",
    "                seq_start_idx=seq_start_idx,\n",
    "                seq_end_idx=seq_end_idx,\n",
    "                **encoder_params\n",
    "            ),\n",
    "            batch_size=loader_batch_size,\n",
    "            shuffle=if_shuffle,\n",
    "            worker_init_fn=worker_seed,\n",
    "        )\n",
    "        for subset, if_shuffle in zip(subset_list, if_shuffle_list)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pre-processing the dataset\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections import Sequence\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from scr.utils import pickle_save, pickle_load, replace_ext\n",
    "from scr.preprocess.seq_loader import SeqLoader\n",
    "from scr.encoding.encoding_classes import AbstractEncoder\n",
    "\n",
    "\n",
    "def get_mut_name(mut_seq: str, parent_seq: str) -> str:\n",
    "    \"\"\"\n",
    "    A function for returning the mutant name\n",
    "\n",
    "    Args:\n",
    "    - mut_seq: str, the full mutant sequence\n",
    "    - parent_seq: str, the full parent sequence\n",
    "\n",
    "    Returns:\n",
    "    - str, parent, indel, or mutant name in the format of\n",
    "        ParentAAMutLocMutAA:ParentAAMutLocMutAA:..., ie. W39W:D40G:G41C:V54Q\n",
    "    \"\"\"\n",
    "\n",
    "    mut_list = []\n",
    "    if parent_seq == mut_seq:\n",
    "        return \"parent\"\n",
    "    elif len(parent_seq) == len(mut_seq):\n",
    "        for i, (p, m) in enumerate(zip(list(parent_seq), list(mut_seq))):\n",
    "            if p != m:\n",
    "                mut_list.append(f\"{p}{i+1}{m}\")\n",
    "        return \":\".join(mut_list)\n",
    "    else:\n",
    "        return \"indel\"\n",
    "\n",
    "\n",
    "class AddMutInfo:\n",
    "    \"\"\"A class for appending mutation info for mainly protein engineering tasks\"\"\"\n",
    "\n",
    "    def __init__(self, parent_seq_path: str, csv_path: str):\n",
    "\n",
    "        # Load the parent sequence from the fasta file\n",
    "        self._parent_seq = SeqLoader(parent_seq_path=parent_seq_path)\n",
    "\n",
    "        # load the dataframe\n",
    "        self._init_df = pd.read_csv(csv_path)\n",
    "\n",
    "        self._df = self._init_df.copy()\n",
    "        # add a column with the mutant names\n",
    "        self._df[\"mut_name\"] = self._init_df[\"sequence\"].apply(\n",
    "            get_mut_name, parent_seq=self._parent_seq\n",
    "        )\n",
    "        # add a column with the number of mutations\n",
    "        self._df[\"mut_numb\"] = (\n",
    "            self._df[\"mut_name\"].str.split(\":\").map(len, na_action=\"ignore\")\n",
    "        )\n",
    "\n",
    "        # get the pickle file path\n",
    "        self._pkl_path = replace_ext(input_path=csv_path, ext=\".pkl\")\n",
    "\n",
    "        pickle_save(what2save=self._df, where2save=self._pkl_path)\n",
    "\n",
    "    @property\n",
    "    def parent_seq(self) -> str:\n",
    "        \"\"\"Return the parent sequence\"\"\"\n",
    "        return self._parent_seq\n",
    "\n",
    "    @property\n",
    "    def pkl_path(self) -> str:\n",
    "        \"\"\"Return the pkl file path for the processed dataframe\"\"\"\n",
    "        return self._pkl_path\n",
    "\n",
    "    @property\n",
    "    def df(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the processed dataframe\"\"\"\n",
    "        return self._df\n",
    "\n",
    "\n",
    "class TaskProcess:\n",
    "    \"\"\"A class for handling different downstream tasks\"\"\"\n",
    "\n",
    "    def __init__(self, data_folder: str = \"data/\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - data_folder: str, a folder path with all the tasks as subfolders where\n",
    "            all the subfolders have datasets as the subsubfolders, ie\n",
    "\n",
    "            {data_folder}/\n",
    "                proeng/\n",
    "                    aav/\n",
    "                        one_vs_many.csv\n",
    "                        two_vs_many.csv\n",
    "                        P03135.fasta\n",
    "                    thermo/\n",
    "                        mixed.csv\n",
    "        \"\"\"\n",
    "\n",
    "        if data_folder[-1] == \"/\":\n",
    "            self._data_folder = data_folder\n",
    "        else:\n",
    "            self._data_folder = data_folder + \"/\"\n",
    "\n",
    "        # sumamarize all files i nthe data folder\n",
    "        self._sum_file_df = self.sum_files()\n",
    "\n",
    "    def sum_files(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Summarize all files in the data folder\n",
    "\n",
    "        Returns:\n",
    "        - A dataframe with \"task\", \"dataset\", \"split\", \"csv_path\", \"fasta_path\", \"pkl_path\" as columns, ie.\n",
    "            (proeng, gb1, low_vs_high, data/proeng/gb1/low_vs_high.csv, data/proeng/gb1/5LDE_1.fasta)\n",
    "            note that csv_path is the list of lmdb files for the structure task\n",
    "        \"\"\"\n",
    "        dataset_folders = glob(f\"{self._data_folder}*/*\")\n",
    "        # need a list of tuples in the order of:\n",
    "        # (task, dataset, split, csv_path, fasta_path)\n",
    "        list_for_df = []\n",
    "        for dataset_folder in dataset_folders:\n",
    "            _, task, dataset = dataset_folder.split(\"/\")\n",
    "            if task == \"structure\":\n",
    "                structure_file_list = [\n",
    "                    file_path\n",
    "                    for file_path in glob(f\"{dataset_folder}/*.*\")\n",
    "                    if os.path.basename(os.path.splitext(file_path)[0]).split(\"_\")[-1]\n",
    "                    in [\"train\", \"valid\", \"cb513\"]\n",
    "                ]\n",
    "                list_for_df.append(\n",
    "                    tuple([task, dataset, \"cb513\", structure_file_list, \"\", \"\"])\n",
    "                )\n",
    "            else:\n",
    "                csv_paths = glob(f\"{dataset_folder}/*.csv\")\n",
    "                fasta_paths = glob(f\"{dataset_folder}/*.fasta\")\n",
    "                pkl_paths = glob(f\"{dataset_folder}/*.pkl\")\n",
    "\n",
    "                assert len(csv_paths) >= 1, \"Less than one csv\"\n",
    "                assert len(fasta_paths) <= 1, \"More than one fasta\"\n",
    "\n",
    "                for csv_path in csv_paths:\n",
    "                    # if parent seq fasta exists\n",
    "                    if len(fasta_paths) == 1:\n",
    "                        fasta_path = fasta_paths[0]\n",
    "\n",
    "                        # if no existing pkl file, generate and save\n",
    "                        if len(pkl_paths) == 0:\n",
    "                            print(f\"Adding mutation info to {csv_path}...\")\n",
    "                            pkl_path = AddMutInfo(\n",
    "                                parent_seq_path=fasta_path, csv_path=csv_path\n",
    "                            ).pkl_path\n",
    "                        # pkl file exits\n",
    "                        else:\n",
    "                            pkl_path = replace_ext(input_path=csv_path, ext=\".pkl\")\n",
    "                    # no parent fasta no pkl file\n",
    "                    else:\n",
    "                        fasta_path = \"\"\n",
    "                        pkl_path = \"\"\n",
    "\n",
    "                    list_for_df.append(\n",
    "                        tuple(\n",
    "                            [\n",
    "                                task,\n",
    "                                dataset,\n",
    "                                os.path.basename(os.path.splitext(csv_path)[0]),\n",
    "                                csv_path,\n",
    "                                fasta_path,\n",
    "                                pkl_path,\n",
    "                            ]\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            list_for_df,\n",
    "            columns=[\"task\", \"dataset\", \"split\", \"csv_path\", \"fasta_path\", \"pkl_path\"],\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def sum_file_df(self) -> pd.DataFrame:\n",
    "        \"\"\"A summary table for all files in the data folder\"\"\"\n",
    "        return self._sum_file_df\n",
    "\n",
    "\n",
    "class ProtranDataset(Dataset):\n",
    "\n",
    "    \"\"\"A dataset class for processing protein transfer data\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        subset: str,\n",
    "        encoder_class: AbstractEncoder,\n",
    "        encoder_name: str,\n",
    "        embed_layer: int,\n",
    "        embed_batch_size: int = 0,\n",
    "        flatten_emb: bool | str = False,\n",
    "        embed_path: str = None,\n",
    "        seq_start_idx: bool | int = False,\n",
    "        seq_end_idx: bool | int = False,\n",
    "        **encoder_params,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dataset_path: str, full path to the dataset, in pkl or panda readable format\n",
    "            columns include: sequence, target, set, validation, mut_name (optional), mut_numb (optional)\n",
    "        - subset: str, train, val, test\n",
    "        - encoder_class: AbstractEncoder, the encoder class\n",
    "        - encoder_name: str, the name of the encoder\n",
    "        - embed_layer: int, the layer number of the embedding\n",
    "        - embed_batch_size: int, set to 0 to encode all in a single batch\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - embed_path: str = None, path to presaved embedding\n",
    "        - seq_start_idx: bool | int = False, the index for the start of the sequence\n",
    "        - seq_end_idx: bool | int = False, the index for the end of the sequence\n",
    "        - encoder_params: kwarg, additional parameters for encoding\n",
    "        \"\"\"\n",
    "\n",
    "        # with additional info mut_name, mut_numb\n",
    "        if os.path.splitext(dataset_path)[-1] in [\".pkl\", \".PKL\", \"\"]:\n",
    "            self._df = pickle_load(dataset_path)\n",
    "            self._add_mut_info = True\n",
    "        # without such info\n",
    "        else:\n",
    "            self._df = pd.read_csv(dataset_path)\n",
    "            self._add_mut_info = False\n",
    "\n",
    "        assert \"set\" in self._df.columns, f\"set is not a column in {dataset_path}\"\n",
    "        assert (\n",
    "            \"validation\" in self._df.columns\n",
    "        ), f\"validation is not a column in {dataset_path}\"\n",
    "\n",
    "        self._df_train = self._df.loc[\n",
    "            (self._df[\"set\"] == \"train\") & (self._df[\"validation\"] != True)\n",
    "        ]\n",
    "        self._df_val = self._df.loc[\n",
    "            (self._df[\"set\"] == \"train\") & (self._df[\"validation\"] == True)\n",
    "        ]\n",
    "        self._df_test = self._df.loc[(self._df[\"set\"] == \"test\")]\n",
    "\n",
    "        self._df_dict = {\n",
    "            \"train\": self._df_train,\n",
    "            \"val\": self._df_val,\n",
    "            \"test\": self._df_test,\n",
    "        }\n",
    "\n",
    "        assert subset in list(\n",
    "            self._df_dict.keys()\n",
    "        ), \"split can only be 'train', 'val', or 'test'\"\n",
    "        self._subset = subset\n",
    "\n",
    "        self._subdf_len = len(self._df_dict[self._subset])\n",
    "\n",
    "        # not specified seq start will be from 0\n",
    "        if seq_start_idx == False:\n",
    "            self._seq_start_idx = 0\n",
    "        else:\n",
    "            self._seq_start_idx = seq_start_idx\n",
    "        # not specified seq end will be the full sequence length\n",
    "        if seq_end_idx == False:\n",
    "            self._seq_end_idx = -1\n",
    "        else:\n",
    "            self._seq_end_idx = seq_end_idx\n",
    "\n",
    "        # get unencoded string of input sequence\n",
    "        # will need to convert data type\n",
    "        self.sequence = self._get_column_value(\"sequence\")\n",
    "\n",
    "        # check if pregenerated embedding\n",
    "        if embed_path is not None:\n",
    "            print(f\"Loading pregenerated embeddings from {embed_path}\")\n",
    "            encoded_sequences = pickle_load(embed_path)\n",
    "\n",
    "        # encode the sequences without the mut_name\n",
    "        else:\n",
    "            encoded_sequences = []\n",
    "\n",
    "            for x in encoder_class(\n",
    "                encoder_name=encoder_name, embed_layer=embed_layer\n",
    "            ).encode(\n",
    "                mut_seqs=self.sequence,\n",
    "                batch_size=embed_batch_size,\n",
    "                flatten_emb=flatten_emb,\n",
    "                **encoder_params,\n",
    "            ):\n",
    "                encoded_sequences.append(x)\n",
    "\n",
    "        self.x = torch.tensor(np.vstack(encoded_sequences), dtype=torch.float32)\n",
    "\n",
    "        # get and format the fitness or secondary structure values\n",
    "        # can be numbers or string\n",
    "        # will need to convert data type\n",
    "        # make 1D tensor 2D\n",
    "        self.y = np.expand_dims(self._get_column_value(\"target\"), 1)\n",
    "\n",
    "        # add mut_name and mut_numb for relevant proeng datasets\n",
    "        if self._add_mut_info:\n",
    "            self.mut_name = self._get_column_value(\"mut_name\")\n",
    "            self.mut_numb = self._get_column_value(\"mut_numb\")\n",
    "        else:\n",
    "            self.mut_name = [\"\"] * self._subdf_len\n",
    "            self.mut_numb = [np.nan] * self._subdf_len\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the selected subset of the dataframe\"\"\"\n",
    "        return self._subdf_len\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        \"\"\"\n",
    "        Return the item in the order of\n",
    "        encoded sequence (x), target (y), sequence, mut_name (optional), mut_numb (optional)\n",
    "        \"\"\"\n",
    "\n",
    "        return (\n",
    "            self.x[idx],\n",
    "            self.y[idx],\n",
    "            self.sequence[idx],\n",
    "            self.mut_name[idx],\n",
    "            self.mut_numb[idx],\n",
    "        )\n",
    "\n",
    "    def _get_column_value(self, column_name: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Check and return the column values of the selected dataframe subset\n",
    "        \"\"\"\n",
    "        if column_name in self._df.columns:\n",
    "            if column_name == \"sequence\":\n",
    "                return (\n",
    "                    self._df_dict[self._subset][column_name]\n",
    "                    .str[self._seq_start_idx : self._seq_end_idx]\n",
    "                    .values\n",
    "                )\n",
    "            else:\n",
    "                return self._df_dict[self._subset][column_name].values\n",
    "\n",
    "    @property\n",
    "    def df_full(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the full loaded dataset\"\"\"\n",
    "        return self._df\n",
    "\n",
    "    @property\n",
    "    def df_train(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the dataset for training only\"\"\"\n",
    "        return self._df_train\n",
    "\n",
    "    @property\n",
    "    def df_val(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the dataset for validation only\"\"\"\n",
    "        return self._df_val\n",
    "\n",
    "    @property\n",
    "    def df_test(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the dataset for training only\"\"\"\n",
    "        return self._df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading esm1b_t33_650M_UR50S using 0 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 12/12 [05:47<00:00, 28.96s/it]\n",
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading esm1b_t33_650M_UR50S using 0 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 14.57s/it]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_split_loader(dataset_path, subset_list = [\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from scr.params.train_test import *\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "# seed everything\n",
    "RAND_SEED = 42\n",
    "random.seed(RAND_SEED)\n",
    "np.random.seed(RAND_SEED)\n",
    "torch.manual_seed(RAND_SEED)\n",
    "torch.cuda.manual_seed(RAND_SEED)\n",
    "torch.cuda.manual_seed_all(RAND_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def run_epoch(\n",
    "        model: nn.Module,\n",
    "        loader: DataLoader,\n",
    "        device: torch.device | str = DEVICE,\n",
    "        criterion: nn.Module | None = None,\n",
    "        optimizer: torch.optim.Optimizer | None = None\n",
    "        ) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs one epoch.\n",
    "    \n",
    "    Args:\n",
    "    - model: nn.Module, already moved to device\n",
    "    - loader: torch.utils.data.DataLoader\n",
    "    - device: torch.device or str\n",
    "    - criterion: optional nn.Module, loss function, already moved to device\n",
    "    - optimizer: optional torch.optim.Optimizer, must also provide criterion,\n",
    "        only provided for training\n",
    "\n",
    "    Returns: \n",
    "    - float, average loss over batches\n",
    "    \"\"\"\n",
    "    if optimizer is not None:\n",
    "        assert criterion is not None\n",
    "        model.train()\n",
    "        is_train = True\n",
    "    else:\n",
    "        model.eval()\n",
    "        is_train = False\n",
    "\n",
    "    cum_loss = 0.\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for (x, y, _, _, _) in loader:\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(x)\n",
    "\n",
    "            if criterion is not None:\n",
    "                loss = criterion(outputs, y.float())\n",
    "\n",
    "                if optimizer is not None:\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "    return cum_loss / len(loader)\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          train_loader: DataLoader,\n",
    "          val_loader: DataLoader,\n",
    "          criterion: nn.Module,\n",
    "          device: torch.device | str = DEVICE,\n",
    "          learning_rate: float = 1e-4,\n",
    "          lr_decay: float = 0.1,\n",
    "          epochs: int = 100,\n",
    "          ) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - model: nn.Module, already moved to device\n",
    "    - train_loader: torch.utils.data.DataLoader, \n",
    "    - val_loader: torch.utils.data.DataLoader, \n",
    "    - criterion: nn.Module, loss function, already moved to device\n",
    "    - device: torch.device or str\n",
    "    - learning_rate: float\n",
    "    - lr_decay: float, factor by which to decay LR on plateau\n",
    "    - epochs: int, number of epochs to train for\n",
    "\n",
    "    Returns: \n",
    "    - tuple of np.ndarray, (train_losses, val_losses)\n",
    "        train/val_losses: np.ndarray, shape [epochs], entries are average loss\n",
    "        over batches for that epoch\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=lr_decay)\n",
    "\n",
    "    train_losses = np.zeros(epochs)\n",
    "    val_losses = np.zeros(epochs)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_losses[epoch] = run_epoch(\n",
    "            model=model, loader=train_loader, device=device,\n",
    "            criterion=criterion, optimizer=optimizer)\n",
    "\n",
    "        val_loss = run_epoch(\n",
    "            model=model, loader=val_loader, device=device,\n",
    "            criterion=criterion)\n",
    "        val_losses[epoch] = val_loss\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def test(model: nn.Module,\n",
    "         loader: DataLoader,\n",
    "         criterion: nn.Module | None,\n",
    "         device: torch.device | str = DEVICE,\n",
    "         print_every: int = 1000,\n",
    "         ) -> tuple[float, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Runs one epoch of testing, returning predictions and labels.\n",
    "    \n",
    "    Args:\n",
    "    - model: nn.Module, already moved to device\n",
    "    - device: torch.device or str\n",
    "    - loader: torch.utils.data.DataLoader\n",
    "    - criterion: optional nn.Module, loss function, already moved to device\n",
    "    - print_every: int, how often (number of batches) to print avg loss\n",
    "    \n",
    "    Returns: tuple (avg_loss, preds, labels)\n",
    "    - avg_loss: float, average loss per training example \n",
    "    - preds: np.ndarray, shape [num_examples, ...], predictions over dataset\n",
    "    - labels: np.ndarray, shape [num_examples, ...], dataset labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    msg = \"[{step:5d}] loss: {loss:.3f}\"\n",
    "\n",
    "    cum_loss = 0.0\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (x, y, _, _, _) in enumerate(tqdm(loader)):\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(x)\n",
    "            preds.append(outputs.detach().cpu().squeeze().numpy())\n",
    "            labels.append(y.detach().cpu().squeeze().numpy())\n",
    "\n",
    "            if criterion is not None:\n",
    "                loss = criterion(outputs, y)\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "                if ((i + 1) % print_every == 0) or (i + 1 == len(loader)):\n",
    "                    tqdm.write(msg.format(step=i + 1, loss=cum_loss / len(loader)))\n",
    "\n",
    "    avg_loss = cum_loss / len(loader)\n",
    "    return avg_loss, np.concatenate(preds), np.concatenate(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2daaab2d2f2f4170bde2b538cd652548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc5936e613141bb9dd98004603c4cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   12] loss: 0.991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_losses, val_losses = train(\n",
    "    model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "    device=DEVICE, criterion=criterion, learning_rate=learning_rate,\n",
    "    epochs=epochs)\n",
    "\n",
    "train_mse = test(\n",
    "    model=model, loader=train_loader, device=DEVICE,\n",
    "    criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f55968b1880>,\n",
       " <matplotlib.lines.Line2D at 0x7f55968b1760>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_losses, range(epochs), val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading esm1b_t33_650M_UR50S using 33 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n",
      "100%|██████████| 12/12 [04:22<00:00, 21.89s/it]\n",
      "Using cache found in /home/t-fli/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading esm1b_t33_650M_UR50S using 33 layer embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:29<00:00, 14.68s/it]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(input_dim=1280, output_dim=1)\n",
    "model.to(DEVICE)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "criterion.to(DEVICE, non_blocking=True)\n",
    "\n",
    "train_loader, val_loader = get_split_loader(dataset_path, subset_list = [\"train\", \"val\"], embed_layer=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36428f8f2440467fa37a8fdd5dd8e3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eb464343444979a1c9401909cb6086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   12] loss: 0.914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_losses, val_losses = train(\n",
    "    model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "    device=DEVICE, criterion=criterion, learning_rate=learning_rate,\n",
    "    epochs=epochs)\n",
    "\n",
    "train_mse = test(\n",
    "    model=model, loader=train_loader, device=DEVICE,\n",
    "    criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f55966f0670>,\n",
       " <matplotlib.lines.Line2D at 0x7f55966f06d0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_losses, range(epochs), val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
