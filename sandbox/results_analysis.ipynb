{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Analyzing per layer output\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scr.params.emb import TRANSFORMER_INFO\n",
    "from scr.utils import pickle_load, get_filename, checkNgen_folder\n",
    "\n",
    "\n",
    "class LayerLoss:\n",
    "    \"\"\"A class for handling layer analysis\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_path: str = \"results/train_val_test\",\n",
    "        output_path: str = \"results/analysis_layer\",\n",
    "        metric_list: list[str] = [\"train_mse\", \"test_ndcg\", \"test_rho\"],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - input_path: str = \"results/train_val_test\",\n",
    "        - output_path: str = \"results/analysis_layer\"\n",
    "        - metric_list: list[str] = [\"train_mse\", \"test_ndcg\", \"test_rho\"]\n",
    "        \"\"\"\n",
    "        # get rid of the last \"/\" if any\n",
    "        self._input_path = os.path.normpath(input_path)\n",
    "        # get the list of subfolders for each dataset\n",
    "        self._dataset_folders = glob(f\"{self._input_path}/*/*/*/*/*\")\n",
    "        # glob(\"results/train_val_test/*/*/*/*/*\")\n",
    "\n",
    "        # get rid of the last \"/\" if any\n",
    "        self._output_path = os.path.normpath(output_path)\n",
    "        self._metric_list = metric_list\n",
    "\n",
    "        # init a dictionary for recording outputs\n",
    "        self._layer_analysis_dict = {}\n",
    "\n",
    "        for dataset_folder in self._dataset_folders:\n",
    "            # dataset_folder = \"results/train_val_test/proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S/max\"\n",
    "            # get the details for the dataset such as proeng/gb1/two_vs_rest\n",
    "            task_subfolder = dataset_folder.split(self._input_path + \"/\")[-1]\n",
    "            # task_subfolder = \"proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S/max\"\n",
    "            task, dataset, split, encoder_name, flatten_emb = task_subfolder.split(\"/\")\n",
    "\n",
    "            self._layer_analysis_dict[dataset_folder] = self.parse_result_dicts(\n",
    "                dataset_folder, task, dataset, split, encoder_name, flatten_emb\n",
    "            )\n",
    "\n",
    "    def parse_result_dicts(\n",
    "        self,\n",
    "        folder_path: str,\n",
    "        task: str,\n",
    "        dataset: str,\n",
    "        split: str,\n",
    "        encoder_name: str,\n",
    "        flatten_emb: bool | str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parse the output result dictionaries for plotting\n",
    "\n",
    "        Args:\n",
    "        - folder_path: str, the folder path for the datasets\n",
    "\n",
    "        Returns:\n",
    "        - output_numb_dict: dict, metric name as keys and the array of losses as values\n",
    "        - output_numb_details: dict, details as folder_path, encoder_name, flatten_emb\n",
    "        \"\"\"\n",
    "\n",
    "        # get the list of output pickle files\n",
    "        pkl_list = glob(f\"{folder_path}/*.pkl\")\n",
    "\n",
    "        # get the max layer number for the array\n",
    "        max_layer_numb = TRANSFORMER_INFO[encoder_name][1] + 1\n",
    "\n",
    "        # init the ouput dict\n",
    "        output_numb_dict = {\n",
    "            metric: np.zeros([max_layer_numb]) for metric in self._metric_list\n",
    "        }\n",
    "\n",
    "        # loop through the list of the pickle files\n",
    "        for pkl_file in pkl_list:\n",
    "            # get the layer number\n",
    "            layer_numb = int(get_filename(pkl_file).split(\"-\")[-1].split(\"_\")[-1])\n",
    "            # load the result dictionary\n",
    "            result_dict = pickle_load(pkl_file)\n",
    "\n",
    "            # populate the processed dictionary\n",
    "            for metric in self._metric_list:\n",
    "                subset, kind = metric.split(\"_\")\n",
    "                if kind == \"rho\":\n",
    "                    output_numb_dict[metric][layer_numb] = result_dict[subset][kind][0]\n",
    "                else:\n",
    "                    output_numb_dict[metric][layer_numb] = result_dict[subset][kind]\n",
    "\n",
    "            # get some details for plotting and saving\n",
    "            output_subfolder = checkNgen_folder(\n",
    "                folder_path.replace(self._input_path, self._output_path)\n",
    "            )\n",
    "\n",
    "        for metric in output_numb_dict.keys():\n",
    "\n",
    "            plot_name = f\"{encoder_name}_{flatten_emb}_{metric}\"\n",
    "            plot_prefix = f\"{task}_{dataset}_{split}\"\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(output_numb_dict[metric])\n",
    "            plt.title(f\"{plot_prefix} \\n {plot_name}\")\n",
    "            plt.xlabel(\"layers\")\n",
    "            plt.ylabel(\"loss\")\n",
    "\n",
    "            for plot_ext in [\".svg\", \".png\"]:\n",
    "                plt.savefig(\n",
    "                    os.path.join(output_subfolder, plot_name + plot_ext),\n",
    "                    bbox_inches=\"tight\",\n",
    "                )\n",
    "            plt.close()\n",
    "\n",
    "        output_numb_details = {\n",
    "            \"folder_path\": output_subfolder,\n",
    "            \"encoder_name\": encoder_name,\n",
    "            \"flatten_emb\": flatten_emb,\n",
    "        }\n",
    "\n",
    "        return output_numb_dict, output_numb_details\n",
    "\n",
    "    @property\n",
    "    def layer_analysis_dict(self) -> dict:\n",
    "        \"\"\"Return a dict with dataset name as the key\"\"\"\n",
    "        return self._layer_analysis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/train_val_test/proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S/max',\n",
       " 'results/train_val_test/proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S/mean',\n",
       " 'results/train_val_test/proeng/gb1/two_vs_rest/esm1_t6_43M_UR50S/max',\n",
       " 'results/train_val_test/proeng/gb1/two_vs_rest/esm1_t6_43M_UR50S/mean',\n",
       " 'results/train_val_test/proeng/gb1/low_vs_high/esm1b_t33_650M_UR50S/max',\n",
       " 'results/train_val_test/proeng/gb1/low_vs_high/esm1b_t33_650M_UR50S/mean',\n",
       " 'results/train_val_test/proeng/gb1/low_vs_high/esm1_t6_43M_UR50S/max',\n",
       " 'results/train_val_test/proeng/gb1/low_vs_high/esm1_t6_43M_UR50S/mean']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"results/train_val_test/*/*/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making results/analysis_layer/proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S...\n",
      "Making results/analysis_layer/proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S/max...\n",
      "Making results/analysis_layer/proeng/gb1/two_vs_rest/esm1b_t33_650M_UR50S/mean...\n",
      "Making results/analysis_layer/proeng/gb1/two_vs_rest/esm1_t6_43M_UR50S...\n",
      "Making results/analysis_layer/proeng/gb1/two_vs_rest/esm1_t6_43M_UR50S/max...\n",
      "Making results/analysis_layer/proeng/gb1/two_vs_rest/esm1_t6_43M_UR50S/mean...\n",
      "Making results/analysis_layer/proeng/gb1/low_vs_high/esm1b_t33_650M_UR50S...\n",
      "Making results/analysis_layer/proeng/gb1/low_vs_high/esm1b_t33_650M_UR50S/max...\n",
      "Making results/analysis_layer/proeng/gb1/low_vs_high/esm1b_t33_650M_UR50S/mean...\n",
      "Making results/analysis_layer/proeng/gb1/low_vs_high/esm1_t6_43M_UR50S...\n",
      "Making results/analysis_layer/proeng/gb1/low_vs_high/esm1_t6_43M_UR50S/max...\n",
      "Making results/analysis_layer/proeng/gb1/low_vs_high/esm1_t6_43M_UR50S/mean...\n"
     ]
    }
   ],
   "source": [
    "layer_analysis_dict = LayerLoss().layer_analysis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.analysis.perlayer import LayerLoss\n",
    "layer_analysis_dict = LayerLoss().layer_analysis_dict\n",
    "layer_analysis_dict.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
