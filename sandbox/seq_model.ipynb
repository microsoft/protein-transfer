{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-fli/repo/protein-transfer\n"
     ]
    }
   ],
   "source": [
    "%cd ~/repo/protein-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_models.pretrained import load_model_and_alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, collater = load_model_and_alphabet('carp_640M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  2, 14,  3, 13, 27, 27, 27],\n",
       "        [10,  5, 16, 14, 14,  9,  9, 12]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [['MDREQ'], ['MGTRRLLP']]\n",
    "x = collater(seqs)[0]  # (n, max_len)\n",
    "x\n",
    "# rep = model(x)  # (n, max_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -1.0284,  -8.3767,   7.8792,  ...,   7.2597,  -1.1452,  -0.8462],\n",
       "         [  4.6713,  15.8570,   1.1478,  ...,   0.7353, -11.8218,   3.7328],\n",
       "         [  8.4552,  17.9306,   0.5176,  ...,   3.0368,  -8.7715,   0.5799],\n",
       "         ...,\n",
       "         [ 15.8914,  32.4650,   1.8229,  ...,  -1.0857,  -3.7955,   3.6075],\n",
       "         [ 22.5673,  29.2003,  -4.6042,  ...,  -1.7818,  -3.7571,   9.1396],\n",
       "         [ 15.0128,  30.3642,   0.1932,  ...,  -5.9510,   7.3621,   8.7913]],\n",
       "\n",
       "        [[ -0.3449, -18.9636,   1.3514,  ...,   3.3504,  -1.8757,   2.4882],\n",
       "         [ 10.1161,  24.4867,  20.2836,  ...,  18.4754,  -9.3882,   4.8050],\n",
       "         [ 18.6814,  -3.9989,  -4.1916,  ...,  -2.4737,  -3.2648,   4.1230],\n",
       "         ...,\n",
       "         [ 13.9370,  16.6294,  10.2726,  ...,  -6.0374, -15.9087,  -4.9570],\n",
       "         [ 12.7606,  14.4539,   7.7045,  ...,  -7.9381, -13.7480,  -6.9303],\n",
       "         [  9.8845,  -6.2927,   0.5083,  ...,   1.9903,  -7.2040,   3.5530]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ByteNetBlock(\n",
       "  (conv): MaskedConv1d(1280, 1280, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (sequence1): Sequential(\n",
       "    (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): GELU()\n",
       "    (2): PositionFeedForward(\n",
       "      (conv): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): GELU()\n",
       "  )\n",
       "  (sequence2): Sequential(\n",
       "    (0): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): GELU()\n",
       "    (2): PositionFeedForward(\n",
       "      (conv): Conv1d(1280, 1280, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embedder.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f9d869a4520>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embedder.layers[0].register_forward_hook(lambda m, input, output: output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5807, -3.8715,  0.3539,  ...,  0.5167,  0.7709,  0.3575],\n",
      "         [ 0.2141,  0.5058, -0.6233,  ...,  0.1069,  0.3125,  0.1335],\n",
      "         [-0.4885,  1.5820, -0.7261,  ...,  0.6289, -0.1414,  0.0143],\n",
      "         ...,\n",
      "         [-0.1115,  1.1351, -0.5492,  ...,  0.9252, -0.5605, -0.8744],\n",
      "         [-0.5841,  0.9891, -0.4321,  ...,  0.6899, -0.4982, -0.8168],\n",
      "         [ 0.3778,  1.1565, -0.6100,  ...,  0.1163, -0.5558,  0.1095]],\n",
      "\n",
      "        [[ 0.0379, -4.0834, -0.4890,  ...,  0.3069,  0.8966,  0.5201],\n",
      "         [ 0.0405,  0.7682,  0.2539,  ...,  0.1911, -0.5259,  0.1394],\n",
      "         [ 0.2669, -3.0594, -0.4116,  ...,  0.1007,  0.1165,  0.1414],\n",
      "         ...,\n",
      "         [-0.0587,  0.2477,  0.8138,  ...,  0.4770, -0.2852,  0.0514],\n",
      "         [-0.3768,  0.9766, -0.2094,  ...,  0.1544,  0.0924, -0.0869],\n",
      "         [-0.5286, -2.1833, -1.1581,  ..., -0.2358, -0.1124,  0.3132]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ -1.0284,  -8.3767,   7.8792,  ...,   7.2597,  -1.1452,  -0.8462],\n",
       "         [  4.6713,  15.8570,   1.1478,  ...,   0.7353, -11.8218,   3.7328],\n",
       "         [  8.4552,  17.9306,   0.5176,  ...,   3.0368,  -8.7715,   0.5799],\n",
       "         ...,\n",
       "         [ 15.8914,  32.4650,   1.8229,  ...,  -1.0857,  -3.7955,   3.6075],\n",
       "         [ 22.5673,  29.2003,  -4.6042,  ...,  -1.7818,  -3.7571,   9.1396],\n",
       "         [ 15.0128,  30.3642,   0.1932,  ...,  -5.9510,   7.3621,   8.7913]],\n",
       "\n",
       "        [[ -0.3449, -18.9636,   1.3514,  ...,   3.3504,  -1.8757,   2.4882],\n",
       "         [ 10.1161,  24.4867,  20.2836,  ...,  18.4754,  -9.3882,   4.8050],\n",
       "         [ 18.6814,  -3.9989,  -4.1916,  ...,  -2.4737,  -3.2648,   4.1230],\n",
       "         ...,\n",
       "         [ 13.9370,  16.6294,  10.2726,  ...,  -6.0374, -15.9087,  -4.9570],\n",
       "         [ 12.7606,  14.4539,   7.7045,  ...,  -7.9381, -13.7480,  -6.9303],\n",
       "         [  9.8845,  -6.2927,   0.5083,  ...,   1.9903,  -7.2040,   3.5530]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5807, -3.8715,  0.3539,  ...,  0.5167,  0.7709,  0.3575],\n",
      "         [ 0.2141,  0.5058, -0.6233,  ...,  0.1069,  0.3125,  0.1335],\n",
      "         [-0.4885,  1.5820, -0.7261,  ...,  0.6289, -0.1414,  0.0143],\n",
      "         ...,\n",
      "         [-0.1115,  1.1351, -0.5492,  ...,  0.9252, -0.5605, -0.8744],\n",
      "         [-0.5841,  0.9891, -0.4321,  ...,  0.6899, -0.4982, -0.8168],\n",
      "         [ 0.3778,  1.1565, -0.6100,  ...,  0.1163, -0.5558,  0.1095]],\n",
      "\n",
      "        [[ 0.0379, -4.0834, -0.4890,  ...,  0.3069,  0.8966,  0.5201],\n",
      "         [ 0.0405,  0.7682,  0.2539,  ...,  0.1911, -0.5259,  0.1394],\n",
      "         [ 0.2669, -3.0594, -0.4116,  ...,  0.1007,  0.1165,  0.1414],\n",
      "         ...,\n",
      "         [-0.0587,  0.2477,  0.8138,  ...,  0.4770, -0.2852,  0.0514],\n",
      "         [-0.3768,  0.9766, -0.2094,  ...,  0.1544,  0.0924, -0.0869],\n",
      "         [-0.5286, -2.1833, -1.1581,  ..., -0.2358, -0.1124,  0.3132]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rep = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7ff69dc400a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embedder.layers[0].register_forward_hook(get_activation(\"layer0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5807, -3.8715,  0.3539,  ...,  0.5167,  0.7709,  0.3575],\n",
       "         [ 0.2141,  0.5058, -0.6233,  ...,  0.1069,  0.3125,  0.1335],\n",
       "         [-0.4885,  1.5820, -0.7261,  ...,  0.6289, -0.1414,  0.0143],\n",
       "         ...,\n",
       "         [-0.1115,  1.1351, -0.5492,  ...,  0.9252, -0.5605, -0.8744],\n",
       "         [-0.5841,  0.9891, -0.4321,  ...,  0.6899, -0.4982, -0.8168],\n",
       "         [ 0.3778,  1.1565, -0.6100,  ...,  0.1163, -0.5558,  0.1095]],\n",
       "\n",
       "        [[ 0.0379, -4.0834, -0.4890,  ...,  0.3069,  0.8966,  0.5201],\n",
       "         [ 0.0405,  0.7682,  0.2539,  ...,  0.1911, -0.5259,  0.1394],\n",
       "         [ 0.2669, -3.0594, -0.4116,  ...,  0.1007,  0.1165,  0.1414],\n",
       "         ...,\n",
       "         [-0.0587,  0.2477,  0.8138,  ...,  0.4770, -0.2852,  0.0514],\n",
       "         [-0.3768,  0.9766, -0.2094,  ...,  0.1544,  0.0924, -0.0869],\n",
       "         [-0.5286, -2.1833, -1.1581,  ..., -0.2358, -0.1124,  0.3132]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[\"layer0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 1280])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[\"layer0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7ff69dc40130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embedder.layers[30].register_forward_hook(get_activation(\"layer30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3.1358, -1.4431, -1.5922,  ...,  1.7289,  3.0116, -0.9578],\n",
       "          [ 3.5927, 11.8457, -3.2833,  ...,  3.9837,  1.6558, -2.8215],\n",
       "          [ 4.8968,  8.8671, -2.4634,  ...,  2.5336,  1.5940, -0.4302],\n",
       "          ...,\n",
       "          [10.9340, 10.5128, -1.2239,  ...,  2.5296,  0.4757,  5.3715],\n",
       "          [10.7995,  7.4243, -3.9322,  ..., -0.1993,  1.3902,  4.4353],\n",
       "          [10.1016, 10.2742, -4.0287,  ...,  0.4354,  4.8301,  6.8638]],\n",
       " \n",
       "         [[ 3.6099, -8.4282, -2.6635,  ...,  1.7940,  4.2331, -0.1905],\n",
       "          [ 3.9157, 10.3297,  0.8302,  ...,  4.3193,  3.1261,  0.9150],\n",
       "          [ 4.3559, -6.4370, -3.3311,  ...,  2.5390,  3.0527,  1.4069],\n",
       "          ...,\n",
       "          [ 3.3398,  9.6685,  0.7930,  ...,  3.5631,  0.7518, -0.7545],\n",
       "          [ 0.7680,  9.1693, -0.7720,  ...,  3.2202,  1.5689, -3.2954],\n",
       "          [ 1.5965, -2.5849, -2.3010,  ...,  3.4427,  2.7374, -2.5098]]]),\n",
       " torch.Size([2, 8, 1280]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[\"layer30\"], activation[\"layer30\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add encoding classes with class methods\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from collections.abc import Iterable, Sequence\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from sequence_models.pretrained import load_model_and_alphabet\n",
    "\n",
    "from scr.params.emb import TRANSFORMER_INFO, TRANSFORMER_MAX_SEQ_LEN, CARP_INFO\n",
    "from scr.params.sys import DEVICE\n",
    "\n",
    "\n",
    "class AbstractEncoder(ABC):\n",
    "    \"\"\"\n",
    "    An abstract encoder class to fill in for different kinds of encoders\n",
    "\n",
    "    All encoders will have an \"encode\" function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_name: str, embed_layer: int):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - encoder_name: str, the name of the encoder\n",
    "        - embed_layer: int, the layer number of the embedding\n",
    "        \"\"\"\n",
    "\n",
    "        self._encoder_name = encoder_name\n",
    "        self._embed_layer = embed_layer\n",
    "\n",
    "    def encode(\n",
    "        self,\n",
    "        mut_seqs: Sequence[str] | str,\n",
    "        batch_size: int = 0,\n",
    "        flatten_emb: bool | str = False,\n",
    "        mut_names: Sequence[str] | str | None = None,\n",
    "    ) -> Iterable[np.ndarray]:\n",
    "        \"\"\"\n",
    "        A function takes a list of sequences to yield a batch of encoded elements\n",
    "\n",
    "        Args:\n",
    "        - mut_seqs: list of str or str, mutant sequences of the same length\n",
    "        - batch_size: int, set to 0 to encode all in a single batch\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - mut_names: list of str or str or None, mutant names\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(mut_seqs, str):\n",
    "            mut_seqs = [mut_seqs]\n",
    "\n",
    "        # If the batch size is 0, then encode all at once in a single batch\n",
    "        if batch_size == 0:\n",
    "            yield self._encode_batch(\n",
    "                mut_seqs=mut_seqs, flatten_emb=flatten_emb, mut_names=mut_names\n",
    "            )\n",
    "\n",
    "        # Otherwise, yield chunks of encoded sequence\n",
    "        else:\n",
    "\n",
    "            for i in tqdm(range(0, len(mut_seqs), batch_size)):\n",
    "\n",
    "                # figure out what mut_names to feed in\n",
    "                if mut_names is None:\n",
    "                    mut_name_batch = mut_names\n",
    "                else:\n",
    "                    mut_name_batch = mut_names[i : i + batch_size]\n",
    "\n",
    "                yield self._encode_batch(\n",
    "                    mut_seqs=mut_seqs[i : i + batch_size],\n",
    "                    flatten_emb=flatten_emb,\n",
    "                    mut_names=mut_name_batch,\n",
    "                )\n",
    "\n",
    "    def flatten_encode(\n",
    "        self, encoded_mut_seqs: np.ndarray, flatten_emb: bool | str\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Flatten the embedding or just return the encoded mutants.\n",
    "\n",
    "        Args:\n",
    "        - encoded_mut_seqs: np.ndarray, shape [batch_size, seq_len, embed_dim]\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "            - True -> shape [batch_size, seq_len * embed_dim]\n",
    "            - \"max\" or \"mean\" -> shape [batch_size, embed_dim]\n",
    "            - False or everything else -> [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray, shape depends on flatten_emb parameter\n",
    "        \"\"\"\n",
    "        assert encoded_mut_seqs.shape[2] == self._embed_dim, \"Wrong embed dim\"\n",
    "\n",
    "        if flatten_emb is True:\n",
    "            # shape [batch_size, seq_len * embed_dim]\n",
    "            return encoded_mut_seqs.reshape(encoded_mut_seqs.shape[0], -1)\n",
    "\n",
    "        elif isinstance(flatten_emb, str):\n",
    "            if flatten_emb == \"mean\":\n",
    "                # [batch_size, embed_dim]\n",
    "                return encoded_mut_seqs.mean(axis=1)\n",
    "            elif flatten_emb == \"max\":\n",
    "                # [batch_size, embed_dim]\n",
    "                return encoded_mut_seqs.max(axis=1)\n",
    "\n",
    "        else:\n",
    "            print(\"No embedding flattening\")\n",
    "            # [batch_size, seq_len, embed_dim]\n",
    "            return encoded_mut_seqs\n",
    "\n",
    "    @abstractmethod\n",
    "    def _encode_batch(\n",
    "        mut_seqs: Sequence[str] | str,\n",
    "        flatten_emb: bool | str,\n",
    "        mut_names: Sequence[str] | str | None = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encode a single batch of mut_seqs\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def embed_dim(self) -> int:\n",
    "        \"\"\"The dim of the embedding\"\"\"\n",
    "        return self._embed_dim\n",
    "\n",
    "    @property\n",
    "    def embed_layer(self) -> int:\n",
    "        \"\"\"The layer nubmer of the embedding\"\"\"\n",
    "        return self._embed_layer\n",
    "\n",
    "    @property\n",
    "    def encoder_name(self) -> str:\n",
    "        \"\"\"The name of the encoding method\"\"\"\n",
    "        return self._encoder_name\n",
    "\n",
    "\n",
    "class ESMEncoder(AbstractEncoder):\n",
    "    \"\"\"\n",
    "    Build an ESM encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_name: str,\n",
    "        embed_layer: int,\n",
    "        iftrimCLS: bool = True,\n",
    "        iftrimEOS: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        - encoder_name: str, the name of the encoder, one of the keys of TRANSFORMER_INFO\n",
    "        - embed_layer: int, the layer number of the embedding\n",
    "        - iftrimCLS: bool, whether to trim the first classifification token\n",
    "        - iftrimEOS: bool, whether to trim the end of sequence token, if exists\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(encoder_name, embed_layer)\n",
    "\n",
    "        self._iftrimCLS = iftrimCLS\n",
    "        self._iftrimEOS = iftrimEOS\n",
    "\n",
    "        # load model from torch.hub\n",
    "        print(f\"Loading {self._encoder_name} using {self._embed_layer} layer embedding\")\n",
    "        self.model, self.alphabet = torch.hub.load(\n",
    "            \"facebookresearch/esm:main\", model=self._encoder_name\n",
    "        )\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "\n",
    "        # set model to eval mode\n",
    "        self.model.eval()\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "        self._embed_dim, self._max_emb_layer, _ = TRANSFORMER_INFO[self._encoder_name]\n",
    "\n",
    "        assert (\n",
    "            self._embed_layer <= self._max_emb_layer\n",
    "        ), f\"{self._embed_layer} exceeds {self._max_emb_layer}\"\n",
    "\n",
    "        expected_num_layers = int(self._encoder_name.split(\"_\")[-3][1:])\n",
    "        assert (\n",
    "            expected_num_layers == self._max_emb_layer\n",
    "        ), \"Wrong ESM model name or layer\"\n",
    "\n",
    "    def _encode_batch(\n",
    "        self,\n",
    "        mut_seqs: Sequence[str] | str,\n",
    "        flatten_emb: bool | str,\n",
    "        mut_names: Sequence[str] | str | None = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encodes a batch of mutant sequences.\n",
    "\n",
    "        Args:\n",
    "        - mut_seqs: list of str or str, mutant sequences of the same length\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - mut_names: list of str or str or None, mutant names\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray or a tuple(np.ndarray, list[str]) where the list is batch_labels\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(mut_names, str):\n",
    "            mut_names = [mut_names]\n",
    "\n",
    "        # pair the mut_names and mut_seqs\n",
    "        if mut_names is not None:\n",
    "            assert len(mut_names) == len(\n",
    "                mut_seqs\n",
    "            ), \"mutant_name and mut_seqs different length\"\n",
    "            mut_seqs = [(n, m) for (n, m) in zip(mut_names, mut_seqs)]\n",
    "        else:\n",
    "            mut_seqs = [(\"\", m) for m in mut_seqs]\n",
    "\n",
    "        # convert raw mutant sequences to tokens\n",
    "        batch_labels, _, batch_tokens = self.batch_converter(mut_seqs)\n",
    "        batch_tokens = batch_tokens.to(DEVICE)\n",
    "\n",
    "        # Turn off gradients and pass the batch through\n",
    "        with torch.no_grad():\n",
    "            # shape [batch_size, seq_len + pad, embed_dim]\n",
    "            if batch_tokens.shape[1] > TRANSFORMER_MAX_SEQ_LEN:\n",
    "                print(f\"Sequence exceeds {TRANSFORMER_MAX_SEQ_LEN}, chopping the end\")\n",
    "                batch_tokens = batch_tokens[:, :TRANSFORMER_MAX_SEQ_LEN]\n",
    "\n",
    "            encoded_mut_seqs = (\n",
    "                self.model(batch_tokens, repr_layers=[self._embed_layer])[\n",
    "                    \"representations\"\n",
    "                ][self._embed_layer]\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "        # https://github.com/facebookresearch/esm/blob/main/esm/data.py\n",
    "        # from_architecture\n",
    "\n",
    "        # trim off initial classification token [CLS]\n",
    "        # both \"ESM-1\" and \"ESM-1b\" have prepend_bos = True\n",
    "        if self._iftrimCLS and self._encoder_name.split(\"_\")[0] in [\"esm1\", \"esm1b\"]:\n",
    "            encoded_mut_seqs = encoded_mut_seqs[:, 1:, :]\n",
    "\n",
    "        # trim off end-of-sequence token [EOS]\n",
    "        # only \"ESM-1b\" has append_eos = True\n",
    "        if self._iftrimEOS and self._encoder_name.split(\"_\")[0] == \"esm1b\":\n",
    "            encoded_mut_seqs = encoded_mut_seqs[:, :-1, :]\n",
    "\n",
    "        if mut_names is not None:\n",
    "            return self.flatten_encode(encoded_mut_seqs, flatten_emb), batch_labels\n",
    "        else:\n",
    "            return self.flatten_encode(encoded_mut_seqs, flatten_emb)\n",
    "\n",
    "\n",
    "class CARPEncoder(AbstractEncoder):\n",
    "    \"\"\"\n",
    "    Build a CARP encoder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_name: str,\n",
    "        embed_layer: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        - encoder_name: str, the name of the encoder, one of the keys of CARP_INFO\n",
    "        - embed_layer: int, the layer number of the embedding\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(encoder_name, embed_layer)\n",
    "\n",
    "        # load model from torch.hub\n",
    "        print(f\"Loading {self._encoder_name} using {self._embed_layer} layer embedding\")\n",
    "\n",
    "        self.model, self.collater = load_model_and_alphabet(self._encoder_name)\n",
    "\n",
    "        self._embed_dim, self._max_emb_layer = CARP_INFO[self._encoder_name]\n",
    "\n",
    "        assert (\n",
    "            self._embed_layer <= self._max_emb_layer\n",
    "        ), f\"{self._embed_layer} exceeds {self._max_emb_layer}\"\n",
    "\n",
    "    def _encode_batch(\n",
    "        self,\n",
    "        mut_seqs: Sequence[str] | str,\n",
    "        flatten_emb: bool | str,\n",
    "        mut_names: Sequence[str] | str | None = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encodes a batch of mutant sequences.\n",
    "\n",
    "        Args:\n",
    "        - mut_seqs: list of str or str, mutant sequences of the same length\n",
    "        - flatten_emb: bool or str, if and how (one of [\"max\", \"mean\"]) to flatten the embedding\n",
    "        - mut_names: list of str or str or None, mutant names\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray or a tuple(np.ndarray, list[str]) where the list is batch_labels\n",
    "        \"\"\"\n",
    "\n",
    "        mut_seqs = [[m] for m in mut_seqs]\n",
    "        \n",
    "        x = self.collater(mut_seqs)[0]\n",
    "\n",
    "        layer_name = f\"layer{str(self._embed_layer)}\"\n",
    "\n",
    "        activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(model, input, output):\n",
    "                activation[name] = output.detach()\n",
    "\n",
    "            return hook\n",
    "\n",
    "        # convert raw mutant sequences to tokens\n",
    "        self.model.model.embedder.layers[self._embed_layer].register_forward_hook(\n",
    "            get_activation(layer_name)\n",
    "        )\n",
    "\n",
    "        rep = self.model(x)\n",
    "        \n",
    "        encoded_mut_seqs = activation[layer_name].numpy()\n",
    "\n",
    "        return self.flatten_encode(encoded_mut_seqs, flatten_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.utils import pickle_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(\"data/proeng/gb1/two_vs_rest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 43, 8309, 8733)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[(df[\"set\"] == \"train\") & (df[\"validation\"] != True)]\n",
    "df_val = df.loc[(df[\"set\"] == \"train\") & (df[\"validation\"] == True)]\n",
    "df_test = df.loc[(df[\"set\"] == \"test\")]\n",
    "\n",
    "len(df_train), len(df_val), len(df_test), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading carp_640M using 0 layer embedding\n"
     ]
    }
   ],
   "source": [
    "no_flat_encoder = CARPEncoder(\n",
    "    encoder_name=\"carp_640M\",\n",
    "    embed_layer=0,\n",
    ").encode(mut_seqs=list(df_val.sequence))\n",
    "one_emb = next(no_flat_encoder)\n",
    "one_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_flat_encoder = CARPEncoder(\n",
    "    encoder_name=\"carp_640M\",\n",
    "    embed_layer=0,\n",
    ").encode(mut_seqs=list(df_val.sequence),flatten_emb=\"mean\")\n",
    "one_mean_emb = next(mean_flat_encoder)\n",
    "one_mean_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('protran')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "019692f042c79b6731ff84413c6b50d6174007f2b51f86eed1fb032dbd4a337e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
